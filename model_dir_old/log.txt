model: {
  second: {
    voxel_generator {
      point_cloud_range : [0, -40, -3, 70.4, 40, 1]
      #point_cloud_range: [0, -96.0, -20, 96.0, 96.0, 20]
      # point_cloud_range : [0, -32.0, -3, 52.8, 32.0, 1]
      #voxel_size : [0.2, 0.2, 1.0]   # original is 0.05,0.05,0.1
      voxel_size : [0.05, 0.05, 0.1]   # original is 0.05,0.05,0.1
      max_number_of_points_per_voxel : 5   # original is 5
    }

    voxel_feature_extractor: {
      module_class_name: "VoxelFeatureExtractorV3"
      num_filters: [16]
      with_distance: false
      num_input_features: 4
    }
    middle_feature_extractor: {
      module_class_name: "SpMiddleFHD"
      # num_filters_down1: [] # protobuf don't support empty list.
      # num_filters_down2: []
      downsample_factor: 8
      num_input_features: 4
    }
    rpn: {
      module_class_name: "RPNV2"
      layer_nums: [5, 5]
      layer_strides: [1, 2]
      num_filters: [128, 256]
      upsample_strides: [1, 2]
      num_upsample_filters: [256, 256]
      use_groupnorm: false
      num_groups: 32
      num_input_features: 128
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0   #original 1.0
      localization_weight: 2.0
    }
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true # this can help for orientation benchmark
    direction_loss_weight: 0.2 # enough.
    use_aux_classifier: false
    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    #post_center_limit_range: [0, -96.0, -20, 96.0, 96.0, 0]
    post_center_limit_range: [0, -40, -3.0, 70.4, 40, 0.0]
    use_rotate_nms: true
    use_multi_class_nms: false
    nms_pre_max_size: 1000
    nms_post_max_size: 100
    nms_score_threshold: 0.2
    nms_iou_threshold: 0.01

    use_bev: false
    num_point_features: 4
    without_reflectivity: false
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      anchor_generators: {
        anchor_generator_range: {
          sizes: [1.6, 3.9, 1.56] # wlh
          anchor_ranges: [0, -40.0, -1.78, 70.4, 40.0, -1.78] # carefully set z center, the original one is -1.78
          rotations: [0, 1.57] # DON'T modify this unless you are very familiar with my code.
          matched_threshold : 0.6
          unmatched_threshold : 0.45
          class_name: "Car"
        }
      }
      sample_positive_fraction : -1
      sample_size : 512
      region_similarity_calculator: {
        nearest_iou_similarity: {
        }
      }
    }
  }
}


train_input_reader: {
  max_num_epochs : 160
  batch_size: 1
  prefetch_size : 25
  max_number_of_voxels: 16000 # to support batchsize=2 in 1080Ti, original 16000
  shuffle_points: true
  num_workers: 3
  groundtruth_localization_noise_std: [1.0, 1.0, 0.5]
  # groundtruth_rotation_uniform_noise: [-0.3141592654, 0.3141592654]
  # groundtruth_rotation_uniform_noise: [-1.57, 1.57]
  groundtruth_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_scaling_uniform_noise: [0.95, 1.05]
  global_random_rotation_range_per_object: [0, 0] # pi/4 ~ 3pi/4
  anchor_area_threshold: -1
  remove_points_after_sample: true
  groundtruth_points_drop_percentage: 0.0
  groundtruth_drop_max_keep_points: 15
  database_sampler {
    database_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_dbinfos_train.pkl"
    sample_groups {
      name_to_max_num {
        key: "Car"
        value: 15
      }
    }
    database_prep_steps {
      filter_by_min_num_points {
        min_num_point_pairs {
          key: "Car"
          value: 5
        }
      }
    }
    database_prep_steps {
      filter_by_difficulty {
        removed_difficulties: [-1]
      }
    }
    global_random_rotation_range_per_object: [0, 0]
    rate: 1.0
  }

  remove_unknown_examples: false
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_train.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

train_config: {
  optimizer: {
    adam_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3  # original 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0  #original 10
          pct_start: 0.4
        }
      }
      weight_decay: 0.01 # super converge. decrease this when you increase steps. og 0.01
    }
    fixed_weight_decay: true
    use_moving_average: false
  }
  steps: 37120 #112215 #113715 #111360 # 619 * 50, super converge. increase this to achieve slightly better results original 30950
  steps_per_eval: 3712 #7481 # 619 * 5
  save_checkpoints_secs : 1800 # half hour 1800
  save_summary_steps : 10
  enable_mixed_precision: false # for fp16 training, don't use this.
  loss_scale_factor : 512.0
  clear_metrics_every_epoch: true
  detection_2d_path: "../d2_detection_data"
}

eval_input_reader: {
  batch_size: 1
  max_num_epochs : 160
  prefetch_size : 25
  max_number_of_voxels: 16000
  shuffle_points: false
  num_workers: 3
  anchor_area_threshold: -1
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_val.pkl"
  #kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original/data/kitti/kitti_infos_test.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

now it is 50 steps  and the cls_loss is : tensor(3219.7578, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003000725556911313
now it is 100 steps  and the cls_loss is : tensor(910.8961, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300296159683897
now it is 150 steps  and the cls_loss is : tensor(380.5663, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003006708197788306
now it is 200 steps  and the cls_loss is : tensor(275.1325, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003011964940447371
now it is 250 steps  and the cls_loss is : tensor(195.9513, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003018731236492261
now it is 300 steps  and the cls_loss is : tensor(110.8508, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003027006328652909
now it is 350 steps  and the cls_loss is : tensor(80.4304, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003036789290797896
now it is 400 steps  and the cls_loss is : tensor(49.0755, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003048079028038046
now it is 450 steps  and the cls_loss is : tensor(21.6377, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030608742768490054
now it is 500 steps  and the cls_loss is : tensor(13.3230, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003075173605212619
now it is 550 steps  and the cls_loss is : tensor(9.0775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003090975412777231
now it is 600 steps  and the cls_loss is : tensor(5.4434, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000310827793103677
now it is 650 steps  and the cls_loss is : tensor(4.2059, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031270792235286874
now it is 700 steps  and the cls_loss is : tensor(2.0866, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003147377186050681
now it is 750 steps  and the cls_loss is : tensor(1.5586, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031691695468961945
now it is 800 steps  and the cls_loss is : tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031924538671086484
now it is 850 steps  and the cls_loss is : tensor(0.8178, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003217227540754427
now it is 900 steps  and the cls_loss is : tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003243487795214512
now it is 950 steps  and the cls_loss is : tensor(0.3931, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032712316914947906
now it is 1000 steps  and the cls_loss is : tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003300456124554988
now it is 1050 steps  and the cls_loss is : tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003331157823656169
now it is 1100 steps  and the cls_loss is : tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033633333527267927
now it is 1150 steps  and the cls_loss is : tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033969791107472903
now it is 1200 steps  and the cls_loss is : tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003432091332153048
now it is 1250 steps  and the cls_loss is : tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003468666087255885
now it is 1300 steps  and the cls_loss is : tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035066992826837977
now it is 1350 steps  and the cls_loss is : tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035461866618391544
now it is 1400 steps  and the cls_loss is : tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003587123805375023
now it is 1450 steps  and the cls_loss is : tensor(0.0206, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003629506131689812
now it is 1500 steps  and the cls_loss is : tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003673328897440013
now it is 1550 steps  and the cls_loss is : tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003718587198071068
now it is 1600 steps  and the cls_loss is : tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037652759683663023
now it is 1650 steps  and the cls_loss is : tensor(0.0075, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003813389983013779
now it is 1700 steps  and the cls_loss is : tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003862923857191132
now it is 1750 steps  and the cls_loss is : tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003913872047168203
now it is 1800 steps  and the cls_loss is : tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003966228850927501
now it is 1850 steps  and the cls_loss is : tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040199884088023413
now it is 1900 steps  and the cls_loss is : tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040751447041326855
now it is 1950 steps  and the cls_loss is : tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041316915639384635
now it is 2000 steps  and the cls_loss is : tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004189622659610476
now it is 2050 steps  and the cls_loss is : tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042489315076186694
now it is 2100 steps  and the cls_loss is : tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043096114702377607
now it is 2150 steps  and the cls_loss is : tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043716557562901125
now it is 2200 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044350574219057925
now it is 2250 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004499809371299713
now it is 2300 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045659043575657903
now it is 2350 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00046333349834879866
now it is 2400 steps  and the cls_loss is : tensor(8.2797e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047020937023682
now it is 2450 steps  and the cls_loss is : tensor(5.8098e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004772172818870873
now it is 2500 steps  and the cls_loss is : tensor(3.3181e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00048435644898842415
now it is 2550 steps  and the cls_loss is : tensor(2.3794e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004916260725398116
now it is 2600 steps  and the cls_loss is : tensor(1.4755e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004990253389398113
now it is 2650 steps  and the cls_loss is : tensor(1.0239e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005065534200776206
now it is 2700 steps  and the cls_loss is : tensor(9.0951e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005142094734257559
now it is 2750 steps  and the cls_loss is : tensor(5.4467e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005219926421343433
now it is 2800 steps  and the cls_loss is : tensor(3.7917e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005299020551270185
now it is 2850 steps  and the cls_loss is : tensor(2.8672e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005379368271984128
now it is 2900 steps  and the cls_loss is : tensor(2.2668e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005460960591132263
now it is 2950 steps  and the cls_loss is : tensor(1.7017e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005543788377068678
now it is 3000 steps  and the cls_loss is : tensor(1.2548e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005627842359876515
now it is 3050 steps  and the cls_loss is : tensor(9.0468e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005713113132405499
now it is 3100 steps  and the cls_loss is : tensor(7.1653e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005799591151324696
now it is 3150 steps  and the cls_loss is : tensor(5.1160e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005887266738190643
now it is 3200 steps  and the cls_loss is : tensor(3.6730e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005976130080530494
now it is 3250 steps  and the cls_loss is : tensor(3.0425e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006066171232940259
now it is 3300 steps  and the cls_loss is : tensor(2.9404e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006157380118197828
now it is 3350 steps  and the cls_loss is : tensor(1.7245e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006249746528390822
now it is 3400 steps  and the cls_loss is : tensor(1.3564e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006343260126059026
now it is 3450 steps  and the cls_loss is : tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006437910445351355
now it is 3500 steps  and the cls_loss is : tensor(2.4912e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006533686893197138
now it is 3550 steps  and the cls_loss is : tensor(3.7864e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000663057875049171
now it is 3600 steps  and the cls_loss is : tensor(3.5519e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006728575173296052
now it is 3650 steps  and the cls_loss is : tensor(3.2591e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006827665194050424
now it is 3700 steps  and the cls_loss is : tensor(3.3143e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000692783772280184
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0034581329680986803
generate label finished(15.92/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 3750 steps  and the cls_loss is : tensor(3.0584e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007029081548445221
now it is 3800 steps  and the cls_loss is : tensor(2.9374e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131385339978124
now it is 3850 steps  and the cls_loss is : tensor(2.9040e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000723473764776889
now it is 3900 steps  and the cls_loss is : tensor(2.8595e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007339126904838062
now it is 3950 steps  and the cls_loss is : tensor(2.1122e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007444541428152933
now it is 4000 steps  and the cls_loss is : tensor(1.9508e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007550969419935082
now it is 4050 steps  and the cls_loss is : tensor(1.2287e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000765839896898077
now it is 4100 steps  and the cls_loss is : tensor(7.6345e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007766818051994011
now it is 4150 steps  and the cls_loss is : tensor(5.0389e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007876214534932205
now it is 4200 steps  and the cls_loss is : tensor(3.4163e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007986576174364136
now it is 4250 steps  and the cls_loss is : tensor(2.3330e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008097890618840231
now it is 4300 steps  and the cls_loss is : tensor(1.4479e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008210145410274955
now it is 4350 steps  and the cls_loss is : tensor(8.4086e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008323327985341024
now it is 4400 steps  and the cls_loss is : tensor(7.4908e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008437425676875517
now it is 4450 steps  and the cls_loss is : tensor(5.8763e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008552425715297549
now it is 4500 steps  and the cls_loss is : tensor(3.1892e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008668315230037403
now it is 4550 steps  and the cls_loss is : tensor(2.4608e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008785081250976996
now it is 4600 steps  and the cls_loss is : tensor(1.9742e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008902710709901445
now it is 4650 steps  and the cls_loss is : tensor(1.6969e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000902119044196167
now it is 4700 steps  and the cls_loss is : tensor(1.1521e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009140507187147739
now it is 4750 steps  and the cls_loss is : tensor(8.3393e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009260647591772921
now it is 4800 steps  and the cls_loss is : tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009381598209968205
now it is 4850 steps  and the cls_loss is : tensor(1.2842e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009503345505187132
now it is 4900 steps  and the cls_loss is : tensor(1.0960e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000962587585172077
now it is 4950 steps  and the cls_loss is : tensor(6.1190e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009749175536222683
now it is 5000 steps  and the cls_loss is : tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009873230759243697
now it is 5050 steps  and the cls_loss is : tensor(2.8198e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009998027636776313
now it is 5100 steps  and the cls_loss is : tensor(2.5730e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001012355220180857
now it is 5150 steps  and the cls_loss is : tensor(1.5506e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010249790405887204
now it is 5200 steps  and the cls_loss is : tensor(6.0025e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010376728120689927
now it is 5250 steps  and the cls_loss is : tensor(3.7468e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010504351139606636
now it is 5300 steps  and the cls_loss is : tensor(2.4342e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010632645179329393
now it is 5350 steps  and the cls_loss is : tensor(1.4069e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010761595881450979
now it is 5400 steps  and the cls_loss is : tensor(1.0051e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010891188814071855
now it is 5450 steps  and the cls_loss is : tensor(6.2687e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011021409473415357
now it is 5500 steps  and the cls_loss is : tensor(4.4179e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011152243285450926
now it is 5550 steps  and the cls_loss is : tensor(3.2642e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001128367560752521
now it is 5600 steps  and the cls_loss is : tensor(2.3671e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011415691730000822
now it is 5650 steps  and the cls_loss is : tensor(1.6041e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011548276877902644
now it is 5700 steps  and the cls_loss is : tensor(1.3146e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011681416212571375
now it is 5750 steps  and the cls_loss is : tensor(8.7905e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011815094833324265
now it is 5800 steps  and the cls_loss is : tensor(7.1949e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011949297779122777
now it is 5850 steps  and the cls_loss is : tensor(5.6960e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001208401003024697
now it is 5900 steps  and the cls_loss is : tensor(4.0047e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00122192165099765
now it is 5950 steps  and the cls_loss is : tensor(3.3178e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012354902086277964
now it is 6000 steps  and the cls_loss is : tensor(2.4980e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012491051573498436
now it is 6050 steps  and the cls_loss is : tensor(1.7549e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012627649734065047
now it is 6100 steps  and the cls_loss is : tensor(1.5034e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012764681280190307
now it is 6150 steps  and the cls_loss is : tensor(1.1034e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012902130875583106
now it is 6200 steps  and the cls_loss is : tensor(9.2494e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013039983137165102
now it is 6250 steps  and the cls_loss is : tensor(6.8105e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013178222636792386
now it is 6300 steps  and the cls_loss is : tensor(5.2935e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013316833902982158
now it is 6350 steps  and the cls_loss is : tensor(4.4978e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013455801422644254
now it is 6400 steps  and the cls_loss is : tensor(3.1741e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013595109642817347
now it is 6450 steps  and the cls_loss is : tensor(2.5834e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013734742972409612
now it is 6500 steps  and the cls_loss is : tensor(2.0671e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013874685783943645
now it is 6550 steps  and the cls_loss is : tensor(1.7334e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014014922415305432
now it is 6600 steps  and the cls_loss is : tensor(1.4602e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014155437171497274
now it is 6650 steps  and the cls_loss is : tensor(1.1418e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001429621432639428
now it is 6700 steps  and the cls_loss is : tensor(8.8188e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014437238124504453
now it is 6750 steps  and the cls_loss is : tensor(8.1435e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014578492782731974
now it is 6800 steps  and the cls_loss is : tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014719962492143641
now it is 6850 steps  and the cls_loss is : tensor(2.4005e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014861631419738161
now it is 6900 steps  and the cls_loss is : tensor(3.8907e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015003483710218147
now it is 6950 steps  and the cls_loss is : tensor(3.9838e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015145503487764605
now it is 7000 steps  and the cls_loss is : tensor(4.2507e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015287674857813742
now it is 7050 steps  and the cls_loss is : tensor(4.2851e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001542998190883584
now it is 7100 steps  and the cls_loss is : tensor(4.3246e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015572408714116033
now it is 7150 steps  and the cls_loss is : tensor(4.1361e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015714939333536806
now it is 7200 steps  and the cls_loss is : tensor(3.8505e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015857557815361987
now it is 7250 steps  and the cls_loss is : tensor(3.6467e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016000248198022014
now it is 7300 steps  and the cls_loss is : tensor(3.6883e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016142994511900328
now it is 7350 steps  and the cls_loss is : tensor(3.5081e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016285780781120677
now it is 7400 steps  and the cls_loss is : tensor(3.0136e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016428591025335066
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0034264449676645902
generate label finished(15.68/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 7450 steps  and the cls_loss is : tensor(2.5646e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016571409261512285
now it is 7500 steps  and the cls_loss is : tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016714219505726679
now it is 7550 steps  and the cls_loss is : tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001685700577494702
now it is 7600 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016999752088825337
now it is 7650 steps  and the cls_loss is : tensor(9.1569e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017142442471485364
now it is 7700 steps  and the cls_loss is : tensor(5.9832e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017285060953310543
now it is 7750 steps  and the cls_loss is : tensor(4.0697e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017427591572731318
now it is 7800 steps  and the cls_loss is : tensor(2.9187e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001757001837801151
now it is 7850 steps  and the cls_loss is : tensor(2.1358e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017712325429033603
now it is 7900 steps  and the cls_loss is : tensor(1.5775e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001785449679908274
now it is 7950 steps  and the cls_loss is : tensor(1.0346e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017996516576629206
now it is 8000 steps  and the cls_loss is : tensor(1.0041e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018138368867109188
now it is 8050 steps  and the cls_loss is : tensor(8.0093e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001828003779470371
now it is 8100 steps  and the cls_loss is : tensor(5.7967e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018421507504115377
now it is 8150 steps  and the cls_loss is : tensor(4.5522e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018562762162342898
now it is 8200 steps  and the cls_loss is : tensor(3.7394e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001870378596045307
now it is 8250 steps  and the cls_loss is : tensor(3.0119e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018844563115350077
now it is 8300 steps  and the cls_loss is : tensor(1.9888e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018985077871541912
now it is 8350 steps  and the cls_loss is : tensor(1.5698e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019125314502903706
now it is 8400 steps  and the cls_loss is : tensor(1.2323e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019265257314437737
now it is 8450 steps  and the cls_loss is : tensor(9.1080e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019404890644030006
now it is 8500 steps  and the cls_loss is : tensor(7.3422e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00195441988642031
now it is 8550 steps  and the cls_loss is : tensor(6.0538e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019683166383865193
now it is 8600 steps  and the cls_loss is : tensor(4.4176e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019821777650054963
now it is 8650 steps  and the cls_loss is : tensor(3.8843e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001996001714968225
now it is 8700 steps  and the cls_loss is : tensor(2.7863e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020097869411264246
now it is 8750 steps  and the cls_loss is : tensor(2.2778e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002023531900665704
now it is 8800 steps  and the cls_loss is : tensor(1.6162e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00203723505527823
now it is 8850 steps  and the cls_loss is : tensor(1.3570e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020508948713348907
now it is 8900 steps  and the cls_loss is : tensor(1.1034e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002064509820056939
now it is 8950 steps  and the cls_loss is : tensor(7.5992e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002078078377687085
now it is 9000 steps  and the cls_loss is : tensor(5.7774e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002091599025660038
now it is 9050 steps  and the cls_loss is : tensor(4.6421e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002105070250772457
now it is 9100 steps  and the cls_loss is : tensor(3.7657e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021184905453523082
now it is 9150 steps  and the cls_loss is : tensor(2.8007e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021318584074275977
now it is 9200 steps  and the cls_loss is : tensor(2.2695e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021451723408944705
now it is 9250 steps  and the cls_loss is : tensor(1.7644e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021584308556846523
now it is 9300 steps  and the cls_loss is : tensor(1.4546e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021716324679322144
now it is 9350 steps  and the cls_loss is : tensor(1.1240e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021847757001396424
now it is 9400 steps  and the cls_loss is : tensor(7.3767e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021978590813432
now it is 9450 steps  and the cls_loss is : tensor(6.8126e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00221088114727755
now it is 9500 steps  and the cls_loss is : tensor(5.2084e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022238404405396373
now it is 9550 steps  and the cls_loss is : tensor(4.0668e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022367355107517956
now it is 9600 steps  and the cls_loss is : tensor(3.1717e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002249564914724071
now it is 9650 steps  and the cls_loss is : tensor(2.1773e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022623272166157424
now it is 9700 steps  and the cls_loss is : tensor(2.0287e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022750209880960143
now it is 9750 steps  and the cls_loss is : tensor(1.6744e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022876448085038777
now it is 9800 steps  and the cls_loss is : tensor(1.1249e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023001972650071034
now it is 9850 steps  and the cls_loss is : tensor(1.0096e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023126769527603654
now it is 9900 steps  and the cls_loss is : tensor(7.8156e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002325082475062467
now it is 9950 steps  and the cls_loss is : tensor(5.8131e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023374124435126577
now it is 10000 steps  and the cls_loss is : tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023496654781660214
now it is 10050 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002361840207687914
now it is 10100 steps  and the cls_loss is : tensor(7.7675e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023739352695074426
now it is 10150 steps  and the cls_loss is : tensor(4.9269e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002385949309969961
now it is 10200 steps  and the cls_loss is : tensor(3.3668e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023978809844885677
now it is 10250 steps  and the cls_loss is : tensor(2.6046e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00240972895769459
now it is 10300 steps  and the cls_loss is : tensor(1.7472e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024214919035870355
now it is 10350 steps  and the cls_loss is : tensor(1.2856e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002433168505680995
now it is 10400 steps  and the cls_loss is : tensor(9.4953e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00244475745715498
now it is 10450 steps  and the cls_loss is : tensor(7.4986e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024562574609971835
now it is 10500 steps  and the cls_loss is : tensor(5.4994e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024676672301506327
now it is 10550 steps  and the cls_loss is : tensor(3.7457e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024789854876572396
now it is 10600 steps  and the cls_loss is : tensor(3.7438e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024902109668007116
now it is 10650 steps  and the cls_loss is : tensor(3.0407e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025013424112483216
now it is 10700 steps  and the cls_loss is : tensor(2.4486e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025123785751915142
now it is 10750 steps  and the cls_loss is : tensor(1.7106e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025233182234853336
now it is 10800 steps  and the cls_loss is : tensor(1.5296e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025341601317866577
now it is 10850 steps  and the cls_loss is : tensor(1.1731e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025449030866912274
now it is 10900 steps  and the cls_loss is : tensor(8.8416e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002555545885869442
now it is 10950 steps  and the cls_loss is : tensor(7.1418e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025660873382009285
now it is 11000 steps  and the cls_loss is : tensor(5.7959e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002576526263907846
now it is 11050 steps  and the cls_loss is : tensor(4.1255e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025868614946869223
now it is 11100 steps  and the cls_loss is : tensor(3.2691e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002597091873840213
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0036865610431395354
generate label finished(16.07/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 11150 steps  and the cls_loss is : tensor(2.4653e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002607216256404551
now it is 11200 steps  and the cls_loss is : tensor(1.8800e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026172335092796923
now it is 11250 steps  and the cls_loss is : tensor(1.4169e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00262714251135513
now it is 11300 steps  and the cls_loss is : tensor(1.3041e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002636942153635564
now it is 11350 steps  and the cls_loss is : tensor(1.0871e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026466313393650213
now it is 11400 steps  and the cls_loss is : tensor(8.4333e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026562089841495997
now it is 11450 steps  and the cls_loss is : tensor(6.1689e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002665674016078832
now it is 11500 steps  and the cls_loss is : tensor(5.2981e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026750253758456525
now it is 11550 steps  and the cls_loss is : tensor(3.9464e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002684262016864952
now it is 11600 steps  and the cls_loss is : tensor(3.1411e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002693382905390709
now it is 11650 steps  and the cls_loss is : tensor(2.3325e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027023870206316853
now it is 11700 steps  and the cls_loss is : tensor(2.0031e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002711273354865671
now it is 11750 steps  and the cls_loss is : tensor(1.6153e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002720040913552265
now it is 11800 steps  and the cls_loss is : tensor(1.3371e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027286887154441856
now it is 11850 steps  and the cls_loss is : tensor(9.4724e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002737215792697083
now it is 11900 steps  and the cls_loss is : tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027456211909778674
now it is 11950 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002753903969571509
now it is 12000 steps  and the cls_loss is : tensor(6.2031e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027620632014863223
now it is 12050 steps  and the cls_loss is : tensor(3.9519e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002770097973557717
now it is 12100 steps  and the cls_loss is : tensor(2.7236e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002778007386550392
now it is 12150 steps  and the cls_loss is : tensor(1.9078e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002785790555258979
now it is 12200 steps  and the cls_loss is : tensor(1.2931e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002793446608607114
now it is 12250 steps  and the cls_loss is : tensor(9.7663e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002800974689744924
now it is 12300 steps  and the cls_loss is : tensor(7.7319e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028083739561449235
now it is 12350 steps  and the cls_loss is : tensor(6.1000e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002815643579696311
now it is 12400 steps  and the cls_loss is : tensor(4.6089e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028227827467976474
now it is 12450 steps  and the cls_loss is : tensor(3.5465e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002829790658447915
now it is 12500 steps  and the cls_loss is : tensor(2.5928e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028366665303359365
now it is 12550 steps  and the cls_loss is : tensor(2.5172e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002843409592928156
now it is 12600 steps  and the cls_loss is : tensor(1.6610e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002850019091554764
now it is 12650 steps  and the cls_loss is : tensor(1.3784e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028564942864941563
now it is 12700 steps  and the cls_loss is : tensor(1.0050e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002862834453055724
now it is 12750 steps  and the cls_loss is : tensor(7.9778e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002869038881660959
now it is 12800 steps  and the cls_loss is : tensor(5.8700e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028751068779228678
now it is 12850 steps  and the cls_loss is : tensor(5.0746e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028810377627236875
now it is 12900 steps  and the cls_loss is : tensor(3.7698e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028868308722908888
now it is 12950 steps  and the cls_loss is : tensor(3.3519e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028924855582714666
now it is 13000 steps  and the cls_loss is : tensor(2.9377e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028980011878045006
now it is 13050 steps  and the cls_loss is : tensor(2.1049e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029033771435919855
now it is 13100 steps  and the cls_loss is : tensor(1.7546e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002908612823967915
now it is 13150 steps  and the cls_loss is : tensor(1.2177e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002913707642965622
now it is 13200 steps  and the cls_loss is : tensor(9.6677e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918661030383357
now it is 13250 steps  and the cls_loss is : tensor(8.2689e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002923472431848105
now it is 13300 steps  and the cls_loss is : tensor(5.6432e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029281413088776283
now it is 13350 steps  and the cls_loss is : tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029326671389407343
now it is 13400 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002937049415515754
now it is 13450 steps  and the cls_loss is : tensor(6.8921e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029412876481472324
now it is 13500 steps  and the cls_loss is : tensor(3.4647e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029453813625008192
now it is 13550 steps  and the cls_loss is : tensor(2.7425e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002949330100416355
now it is 13600 steps  and the cls_loss is : tensor(2.1305e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002953133419959147
now it is 13650 steps  and the cls_loss is : tensor(1.4920e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00295679089546943
now it is 13700 steps  and the cls_loss is : tensor(1.0883e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002960302117610006
now it is 13750 steps  and the cls_loss is : tensor(7.6769e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002963666693412056
now it is 13800 steps  and the cls_loss is : tensor(5.8869e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029668842463191182
now it is 13850 steps  and the cls_loss is : tensor(5.4841e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029699544162292363
now it is 13900 steps  and the cls_loss is : tensor(3.9654e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029728768595352556
now it is 13950 steps  and the cls_loss is : tensor(3.1929e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002975651249163284
now it is 14000 steps  and the cls_loss is : tensor(2.4349e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029782772746092924
now it is 14050 steps  and the cls_loss is : tensor(2.0698e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029807546419738703
now it is 14100 steps  and the cls_loss is : tensor(1.4924e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029830830739951157
now it is 14150 steps  and the cls_loss is : tensor(1.2977e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002985262310079667
now it is 14200 steps  and the cls_loss is : tensor(9.3555e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029872921063318664
now it is 14250 steps  and the cls_loss is : tensor(6.9353e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002989172235581058
now it is 14300 steps  and the cls_loss is : tensor(5.2313e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990902487407012
now it is 14350 steps  and the cls_loss is : tensor(4.0448e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002992482668163473
now it is 14400 steps  and the cls_loss is : tensor(3.4300e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029939126009998346
now it is 14450 steps  and the cls_loss is : tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00299519212588093
now it is 14500 steps  and the cls_loss is : tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029963210996049455
now it is 14550 steps  and the cls_loss is : tensor(7.5207e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997299395819444
now it is 14600 steps  and the cls_loss is : tensor(3.7815e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981269050355095
now it is 14650 steps  and the cls_loss is : tensor(2.5175e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998803534639998
now it is 14700 steps  and the cls_loss is : tensor(1.9004e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993292089059045
now it is 14750 steps  and the cls_loss is : tensor(1.4150e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029997038690008377
now it is 14800 steps  and the cls_loss is : tensor(1.1992e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999274729936042
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0029967500119863575
generate label finished(15.96/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 14850 steps  and the cls_loss is : tensor(9.1550e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.003000000011154647
now it is 14900 steps  and the cls_loss is : tensor(6.9942e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999961213121653
now it is 14950 steps  and the cls_loss is : tensor(4.9750e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998478054047454
now it is 15000 steps  and the cls_loss is : tensor(4.2641e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029996597936450026
now it is 15050 steps  and the cls_loss is : tensor(3.2941e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993971871944258
now it is 15100 steps  and the cls_loss is : tensor(2.4051e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029990599991154727
now it is 15150 steps  and the cls_loss is : tensor(1.8152e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998648246180409
now it is 15200 steps  and the cls_loss is : tensor(1.3310e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981619488704736
now it is 15250 steps  and the cls_loss is : tensor(1.1255e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997601131374859
now it is 15300 steps  and the cls_loss is : tensor(9.7678e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029969658215895107
now it is 15350 steps  and the cls_loss is : tensor(6.8988e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029962560511157367
now it is 15400 steps  and the cls_loss is : tensor(6.0155e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029954718552586378
now it is 15450 steps  and the cls_loss is : tensor(5.0231e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002994613273025348
now it is 15500 steps  and the cls_loss is : tensor(3.5383e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029936803471231
now it is 15550 steps  and the cls_loss is : tensor(2.8963e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029926731239570954
now it is 15600 steps  and the cls_loss is : tensor(1.9027e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029915916536281994
now it is 15650 steps  and the cls_loss is : tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990435989930447
now it is 15700 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029892061903483693
now it is 15750 steps  and the cls_loss is : tensor(5.7132e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029879023160541327
now it is 15800 steps  and the cls_loss is : tensor(3.1369e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002986524431904495
now it is 15850 steps  and the cls_loss is : tensor(2.8807e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029850726064375834
now it is 15900 steps  and the cls_loss is : tensor(1.6174e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002983546911869479
now it is 15950 steps  and the cls_loss is : tensor(1.4796e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029819474240906315
now it is 16000 steps  and the cls_loss is : tensor(1.0635e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002980274222662078
now it is 16050 steps  and the cls_loss is : tensor(6.4933e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029785273908114916
now it is 16100 steps  and the cls_loss is : tensor(6.5592e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029767070154290364
now it is 16150 steps  and the cls_loss is : tensor(5.3881e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029748131870630475
now it is 16200 steps  and the cls_loss is : tensor(4.0727e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002972845999915528
now it is 16250 steps  and the cls_loss is : tensor(2.8960e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029708055518374616
now it is 16300 steps  and the cls_loss is : tensor(2.5125e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029686919443239457
now it is 16350 steps  and the cls_loss is : tensor(1.8867e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029665052825091436
now it is 16400 steps  and the cls_loss is : tensor(1.4403e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029642456751610546
now it is 16450 steps  and the cls_loss is : tensor(1.0579e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029619132346761032
now it is 16500 steps  and the cls_loss is : tensor(9.6748e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002959508077073548
now it is 16550 steps  and the cls_loss is : tensor(6.6157e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029570303219897134
now it is 16600 steps  and the cls_loss is : tensor(6.7021e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029544800926720356
now it is 16650 steps  and the cls_loss is : tensor(4.4766e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029518575159729324
now it is 16700 steps  and the cls_loss is : tensor(3.4209e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029491627223434957
now it is 16750 steps  and the cls_loss is : tensor(2.9347e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002946395845827
now it is 16800 steps  and the cls_loss is : tensor(2.3705e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002943557024052237
now it is 16850 steps  and the cls_loss is : tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029406463982266672
now it is 16900 steps  and the cls_loss is : tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029376641131293995
now it is 16950 steps  and the cls_loss is : tensor(6.8251e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002934610317103987
now it is 17000 steps  and the cls_loss is : tensor(4.0424e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002931485162051048
now it is 17050 steps  and the cls_loss is : tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029282888034207117
now it is 17100 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002925021400204885
now it is 17150 steps  and the cls_loss is : tensor(4.9293e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002921683114929346
now it is 17200 steps  and the cls_loss is : tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918274113645655
now it is 17250 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029147945659229006
now it is 17300 steps  and the cls_loss is : tensor(5.3527e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029112446448392604
now it is 17350 steps  and the cls_loss is : tensor(3.9295e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029076245269733935
now it is 17400 steps  and the cls_loss is : tensor(2.4786e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00290393439239566
now it is 17450 steps  and the cls_loss is : tensor(1.8468e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029001744246591587
now it is 17500 steps  and the cls_loss is : tensor(1.5252e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028963448107906004
now it is 17550 steps  and the cls_loss is : tensor(1.1367e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002892445741281004
now it is 17600 steps  and the cls_loss is : tensor(6.9530e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002888477410076222
now it is 17650 steps  and the cls_loss is : tensor(8.3125e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002884440014567292
now it is 17700 steps  and the cls_loss is : tensor(4.1514e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002880333755580618
now it is 17750 steps  and the cls_loss is : tensor(3.9906e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002876158837367984
now it is 17800 steps  and the cls_loss is : tensor(4.4225e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002871915467596389
now it is 17850 steps  and the cls_loss is : tensor(2.3706e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002867603857337723
now it is 17900 steps  and the cls_loss is : tensor(1.4410e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028632242210582626
now it is 17950 steps  and the cls_loss is : tensor(1.4010e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002858776776608008
now it is 18000 steps  and the cls_loss is : tensor(1.0109e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028542617452098425
now it is 18050 steps  and the cls_loss is : tensor(8.3724e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002849679351448532
now it is 18100 steps  and the cls_loss is : tensor(6.2966e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028450298232595523
now it is 18150 steps  and the cls_loss is : tensor(4.7281e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028403133919177505
now it is 18200 steps  and the cls_loss is : tensor(2.7551e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002835530292025842
now it is 18250 steps  and the cls_loss is : tensor(2.3064e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00283068076150274
now it is 18300 steps  and the cls_loss is : tensor(2.2777e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028257650415717244
now it is 18350 steps  and the cls_loss is : tensor(1.7337e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002820783376748438
now it is 18400 steps  and the cls_loss is : tensor(1.3142e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028157360148287256
now it is 18450 steps  and the cls_loss is : tensor(8.5175e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002810623206876312
now it is 18500 steps  and the cls_loss is : tensor(6.0724e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028054452072103085
now it is 18550 steps  and the cls_loss is : tensor(4.7968e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028002022733925646
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0037333269253605936
generate label finished(15.94/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 18600 steps  and the cls_loss is : tensor(3.7834e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002794894666214858
now it is 18650 steps  and the cls_loss is : tensor(3.0326e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00278952264968592
now it is 18700 steps  and the cls_loss is : tensor(2.5028e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002784086491018305
now it is 18750 steps  and the cls_loss is : tensor(1.9892e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027785864606150977
now it is 18800 steps  and the cls_loss is : tensor(1.3509e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002773022832056464
now it is 18850 steps  and the cls_loss is : tensor(1.1415e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027673958820860415
now it is 18900 steps  and the cls_loss is : tensor(6.8042e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002761705890597176
now it is 18950 steps  and the cls_loss is : tensor(6.3545e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002755953140618995
now it is 19000 steps  and the cls_loss is : tensor(5.8033e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027501379183023336
now it is 19050 steps  and the cls_loss is : tensor(4.6309e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027442605129055003
now it is 19100 steps  and the cls_loss is : tensor(3.0663e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027383212167798854
now it is 19150 steps  and the cls_loss is : tensor(2.8743e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027323203253554235
now it is 19200 steps  and the cls_loss is : tensor(2.0707e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027262581371258953
now it is 19250 steps  and the cls_loss is : tensor(1.8109e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002720134953634081
now it is 19300 steps  and the cls_loss is : tensor(1.2236e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002713951079456761
now it is 19350 steps  and the cls_loss is : tensor(9.7334e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002707706822189567
now it is 19400 steps  and the cls_loss is : tensor(8.7029e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002701402492431679
now it is 19450 steps  and the cls_loss is : tensor(6.8106e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002695038403770379
now it is 19500 steps  and the cls_loss is : tensor(5.4624e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002688614872765449
now it is 19550 steps  and the cls_loss is : tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026821322189334276
now it is 19600 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026755907647317166
now it is 19650 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002668990835542539
now it is 19700 steps  and the cls_loss is : tensor(5.5923e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026623327596567567
now it is 19750 steps  and the cls_loss is : tensor(0.0273, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00265561686825754
now it is 19800 steps  and the cls_loss is : tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002648843495403894
now it is 19850 steps  and the cls_loss is : tensor(6.5961e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002642012978014039
now it is 19900 steps  and the cls_loss is : tensor(4.1020e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00263512565584866
now it is 19950 steps  and the cls_loss is : tensor(2.7687e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002628181871493995
now it is 20000 steps  and the cls_loss is : tensor(2.7922e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002621181970344804
now it is 20050 steps  and the cls_loss is : tensor(1.5255e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026141263005871824
now it is 20100 steps  and the cls_loss is : tensor(1.0187e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026070152131812455
now it is 20150 steps  and the cls_loss is : tensor(1.0352e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025998490618436695
now it is 20200 steps  and the cls_loss is : tensor(7.2285e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025926282030300954
now it is 20250 steps  and the cls_loss is : tensor(5.5705e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002585352995917402
now it is 20300 steps  and the cls_loss is : tensor(3.9933e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025780238023858384
now it is 20350 steps  and the cls_loss is : tensor(3.6567e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002570640987001021
now it is 20400 steps  and the cls_loss is : tensor(3.0244e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002563204916995803
now it is 20450 steps  and the cls_loss is : tensor(1.8331e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025557159622520064
now it is 20500 steps  and the cls_loss is : tensor(1.6838e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002548174495282022
now it is 20550 steps  and the cls_loss is : tensor(1.0722e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025405808912102824
now it is 20600 steps  and the cls_loss is : tensor(8.9776e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002532935527754602
now it is 20650 steps  and the cls_loss is : tensor(7.4150e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025252387852073865
now it is 20700 steps  and the cls_loss is : tensor(7.2478e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025174910464167213
now it is 20750 steps  and the cls_loss is : tensor(4.5918e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002509692696767323
now it is 20800 steps  and the cls_loss is : tensor(4.6305e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025018441241613726
now it is 20850 steps  and the cls_loss is : tensor(3.1494e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024939457189992196
now it is 20900 steps  and the cls_loss is : tensor(2.1367e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024859978741599647
now it is 20950 steps  and the cls_loss is : tensor(1.9238e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024780009849819135
now it is 21000 steps  and the cls_loss is : tensor(1.5683e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002469955449242916
now it is 21050 steps  and the cls_loss is : tensor(1.3076e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024618616671405785
now it is 21100 steps  and the cls_loss is : tensor(9.2484e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002453720041272357
now it is 21150 steps  and the cls_loss is : tensor(7.7042e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002445530976615532
now it is 21200 steps  and the cls_loss is : tensor(4.6268e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024372948805070627
now it is 21250 steps  and the cls_loss is : tensor(5.0098e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002429012162623329
now it is 21300 steps  and the cls_loss is : tensor(3.8814e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024206832349597486
now it is 21350 steps  and the cls_loss is : tensor(3.7422e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002412308511810288
now it is 21400 steps  and the cls_loss is : tensor(2.3195e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024038884097468535
now it is 21450 steps  and the cls_loss is : tensor(1.3333e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002395423347598569
now it is 21500 steps  and the cls_loss is : tensor(1.5943e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023869137464309445
now it is 21550 steps  and the cls_loss is : tensor(1.2123e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00237836002952493
now it is 21600 steps  and the cls_loss is : tensor(9.4664e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002369762622355863
now it is 21650 steps  and the cls_loss is : tensor(7.6695e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002361121952572302
now it is 21700 steps  and the cls_loss is : tensor(5.6671e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002352438449974757
now it is 21750 steps  and the cls_loss is : tensor(4.6010e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00234371254649431
now it is 21800 steps  and the cls_loss is : tensor(3.8331e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023349446761711276
now it is 21850 steps  and the cls_loss is : tensor(3.6992e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002326135275132875
now it is 21900 steps  and the cls_loss is : tensor(2.3253e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00231728478157302
now it is 21950 steps  and the cls_loss is : tensor(2.0591e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023083936357290377
now it is 22000 steps  and the cls_loss is : tensor(1.4681e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022994622798605106
now it is 22050 steps  and the cls_loss is : tensor(9.7909e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022904911582271315
now it is 22100 steps  and the cls_loss is : tensor(9.6022e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002281480717066605
now it is 22150 steps  and the cls_loss is : tensor(8.7664e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022724314045724516
now it is 22200 steps  and the cls_loss is : tensor(4.6314e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002263343670871711
now it is 22250 steps  and the cls_loss is : tensor(4.4293e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022542179680025572
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.004486007336954033
generate label finished(16.18/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 22300 steps  and the cls_loss is : tensor(4.4124e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022450547498918077
now it is 22350 steps  and the cls_loss is : tensor(3.1199e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002235854472332348
now it is 22400 steps  and the cls_loss is : tensor(2.1166e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00222661759296046
now it is 22450 steps  and the cls_loss is : tensor(2.2639e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002217344571233056
now it is 22500 steps  and the cls_loss is : tensor(2.4220e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002208035868404826
now it is 22550 steps  and the cls_loss is : tensor(1.3736e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021986919475052943
now it is 22600 steps  and the cls_loss is : tensor(8.2402e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021893132733157876
now it is 22650 steps  and the cls_loss is : tensor(1.0040e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002179900312346316
now it is 22700 steps  and the cls_loss is : tensor(8.6936e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021704535328123695
now it is 22750 steps  and the cls_loss is : tensor(5.1811e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002160973404611622
now it is 22800 steps  and the cls_loss is : tensor(5.6960e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021514603993005683
now it is 22850 steps  and the cls_loss is : tensor(5.1079e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021419149900710577
now it is 22900 steps  and the cls_loss is : tensor(3.9914e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021323376517267648
now it is 22950 steps  and the cls_loss is : tensor(3.3388e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021227288606595674
now it is 23000 steps  and the cls_loss is : tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021130890948258497
now it is 23050 steps  and the cls_loss is : tensor(5.0135e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021034188337227325
now it is 23100 steps  and the cls_loss is : tensor(4.8650e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002093718558364216
now it is 23150 steps  and the cls_loss is : tensor(5.6574e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020839887512572593
now it is 23200 steps  and the cls_loss is : tensor(6.2385e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020742298963777757
now it is 23250 steps  and the cls_loss is : tensor(5.2436e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002064442479146562
now it is 23300 steps  and the cls_loss is : tensor(4.6501e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002054626986405149
now it is 23350 steps  and the cls_loss is : tensor(5.6634e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002044783906391589
now it is 23400 steps  and the cls_loss is : tensor(5.5166e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020349137287161683
now it is 23450 steps  and the cls_loss is : tensor(5.2356e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002025016944337054
now it is 23500 steps  and the cls_loss is : tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002015094045535872
now it is 23550 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020051455258932203
now it is 23600 steps  and the cls_loss is : tensor(6.2661e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001995171880264119
now it is 23650 steps  and the cls_loss is : tensor(3.9895e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019851736047533934
now it is 23700 steps  and the cls_loss is : tensor(2.9730e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001975151196690997
now it is 23750 steps  and the cls_loss is : tensor(1.8430e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019651051546072766
now it is 23800 steps  and the cls_loss is : tensor(1.5405e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001955035978208171
now it is 23850 steps  and the cls_loss is : tensor(1.1495e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019449441683503565
now it is 23900 steps  and the cls_loss is : tensor(1.0639e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019348302270163337
now it is 23950 steps  and the cls_loss is : tensor(7.1222e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019246946572894562
now it is 24000 steps  and the cls_loss is : tensor(6.5896e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001914537963328909
now it is 24050 steps  and the cls_loss is : tensor(5.5851e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019043606503446307
now it is 24100 steps  and the cls_loss is : tensor(3.0946e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018941632245721804
now it is 24150 steps  and the cls_loss is : tensor(2.6798e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018839461932475604
now it is 24200 steps  and the cls_loss is : tensor(2.4105e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018737100645819839
now it is 24250 steps  and the cls_loss is : tensor(1.6629e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018634553477365951
now it is 24300 steps  and the cls_loss is : tensor(1.3849e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018531825527971443
now it is 24350 steps  and the cls_loss is : tensor(1.2641e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018428921907486138
now it is 24400 steps  and the cls_loss is : tensor(8.0897e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018325847734498033
now it is 24450 steps  and the cls_loss is : tensor(6.6338e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018222608136078654
now it is 24500 steps  and the cls_loss is : tensor(4.5654e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001811920824752806
now it is 24550 steps  and the cls_loss is : tensor(4.0330e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018015653212119385
now it is 24600 steps  and the cls_loss is : tensor(3.5932e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017911948180843024
now it is 24650 steps  and the cls_loss is : tensor(1.9344e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001780809831215039
now it is 24700 steps  and the cls_loss is : tensor(2.1106e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001770410877169735
now it is 24750 steps  and the cls_loss is : tensor(1.7391e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017599984732087255
now it is 24800 steps  and the cls_loss is : tensor(1.2966e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001749573137261365
now it is 24850 steps  and the cls_loss is : tensor(9.3887e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017391353879002665
now it is 24900 steps  and the cls_loss is : tensor(6.5681e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017286857443155057
now it is 24950 steps  and the cls_loss is : tensor(6.5839e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017182247262887951
now it is 25000 steps  and the cls_loss is : tensor(4.4012e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017077528541676297
now it is 25050 steps  and the cls_loss is : tensor(3.9973e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016972706488394052
now it is 25100 steps  and the cls_loss is : tensor(4.0809e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001686778631705506
now it is 25150 steps  and the cls_loss is : tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001676277324655372
now it is 25200 steps  and the cls_loss is : tensor(6.9379e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016657672500405385
now it is 25250 steps  and the cls_loss is : tensor(6.7201e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016552489306486523
now it is 25300 steps  and the cls_loss is : tensor(3.9011e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016447228896774688
now it is 25350 steps  and the cls_loss is : tensor(3.7161e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016341896507088276
now it is 25400 steps  and the cls_loss is : tensor(2.7008e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016236497376826058
now it is 25450 steps  and the cls_loss is : tensor(1.9564e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016131036748706614
now it is 25500 steps  and the cls_loss is : tensor(1.4503e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016025519868507509
now it is 25550 steps  and the cls_loss is : tensor(1.2305e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001591995198480438
now it is 25600 steps  and the cls_loss is : tensor(1.0196e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015814338348709856
now it is 25650 steps  and the cls_loss is : tensor(0.0281, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015708684213612354
now it is 25700 steps  and the cls_loss is : tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001560299483491479
now it is 25750 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015497275469773147
now it is 25800 steps  and the cls_loss is : tensor(6.3315e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001539153137683498
now it is 25850 steps  and the cls_loss is : tensor(3.9739e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015285767815977833
now it is 25900 steps  and the cls_loss is : tensor(3.5400e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001517999004804764
now it is 25950 steps  and the cls_loss is : tensor(1.9721e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015074203334596984
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0027377499303177584
generate label finished(15.81/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 26000 steps  and the cls_loss is : tensor(1.4339e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014968412937623446
now it is 26050 steps  and the cls_loss is : tensor(1.4211e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014862624119307808
now it is 26100 steps  and the cls_loss is : tensor(8.7014e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014756842141752336
now it is 26150 steps  and the cls_loss is : tensor(9.7097e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014651072266719024
now it is 26200 steps  and the cls_loss is : tensor(5.0243e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014545319755367866
now it is 26250 steps  and the cls_loss is : tensor(3.8574e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014439589867995168
now it is 26300 steps  and the cls_loss is : tensor(3.9862e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001433388786377187
now it is 26350 steps  and the cls_loss is : tensor(2.6371e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014228219000481965
now it is 26400 steps  and the cls_loss is : tensor(2.8791e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001412258853426097
now it is 26450 steps  and the cls_loss is : tensor(1.7943e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014017001719334474
now it is 26500 steps  and the cls_loss is : tensor(1.4562e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013911463807756762
now it is 26550 steps  and the cls_loss is : tensor(1.0995e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013805980049149606
now it is 26600 steps  and the cls_loss is : tensor(9.3645e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013700555690441128
now it is 26650 steps  and the cls_loss is : tensor(6.3514e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001359519597560479
now it is 26700 steps  and the cls_loss is : tensor(5.2700e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013489906145398574
now it is 26750 steps  and the cls_loss is : tensor(4.2955e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013384691437104297
now it is 26800 steps  and the cls_loss is : tensor(3.6343e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001327955708426709
now it is 26850 steps  and the cls_loss is : tensor(2.1230e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013174508316435066
now it is 26900 steps  and the cls_loss is : tensor(2.8190e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013069550358899215
now it is 26950 steps  and the cls_loss is : tensor(2.0434e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012964688432433485
now it is 27000 steps  and the cls_loss is : tensor(1.4363e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012859927753035086
now it is 27050 steps  and the cls_loss is : tensor(1.0823e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001275527353166502
now it is 27100 steps  and the cls_loss is : tensor(1.0869e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012650730973988921
now it is 27150 steps  and the cls_loss is : tensor(7.1124e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012546305280118088
now it is 27200 steps  and the cls_loss is : tensor(4.7901e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012442001644350842
now it is 27250 steps  and the cls_loss is : tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012337825254914116
now it is 27300 steps  and the cls_loss is : tensor(0.0263, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001223378129370543
now it is 27350 steps  and the cls_loss is : tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012129874936035114
now it is 27400 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012026111350368874
now it is 27450 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011922495698070716
now it is 27500 steps  and the cls_loss is : tensor(6.6245e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001181903313314621
now it is 27550 steps  and the cls_loss is : tensor(5.5100e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011715728801986124
now it is 27600 steps  and the cls_loss is : tensor(3.4854e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011612587843110409
now it is 27650 steps  and the cls_loss is : tensor(2.7232e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001150961538691264
now it is 27700 steps  and the cls_loss is : tensor(2.2247e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011406816555404795
now it is 27750 steps  and the cls_loss is : tensor(1.6137e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011304196461962507
now it is 27800 steps  and the cls_loss is : tensor(1.3376e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011201760211070658
now it is 27850 steps  and the cls_loss is : tensor(9.0383e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011099512898069548
now it is 27900 steps  and the cls_loss is : tensor(7.8773e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010997459608901388
now it is 27950 steps  and the cls_loss is : tensor(7.0271e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010895605419857352
now it is 28000 steps  and the cls_loss is : tensor(5.5326e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010793955397325047
now it is 28050 steps  and the cls_loss is : tensor(2.8623e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001069251459753653
now it is 28100 steps  and the cls_loss is : tensor(3.8186e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010591288066316776
now it is 28150 steps  and the cls_loss is : tensor(2.3514e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010490280838832723
now it is 28200 steps  and the cls_loss is : tensor(2.2389e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010389497939342772
now it is 28250 steps  and the cls_loss is : tensor(1.6037e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010288944380946912
now it is 28300 steps  and the cls_loss is : tensor(1.0902e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001018862516533735
now it is 28350 steps  and the cls_loss is : tensor(7.4782e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010088545282549697
now it is 28400 steps  and the cls_loss is : tensor(5.6681e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009988709710714784
now it is 28450 steps  and the cls_loss is : tensor(8.1968e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009889123415811035
now it is 28500 steps  and the cls_loss is : tensor(3.6476e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009789791351417438
now it is 28550 steps  and the cls_loss is : tensor(4.3120e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009690718458467154
now it is 28600 steps  and the cls_loss is : tensor(2.3120e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000959190966500176
now it is 28650 steps  and the cls_loss is : tensor(2.1866e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009493369885926097
now it is 28700 steps  and the cls_loss is : tensor(1.7582e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009395104022763824
now it is 28750 steps  and the cls_loss is : tensor(1.7322e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009297116963413565
now it is 28800 steps  and the cls_loss is : tensor(1.0471e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009199413581905825
now it is 28850 steps  and the cls_loss is : tensor(8.8609e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009101998738160516
now it is 28900 steps  and the cls_loss is : tensor(7.4521e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000900487727774525
now it is 28950 steps  and the cls_loss is : tensor(9.5290e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008908054031634252
now it is 29000 steps  and the cls_loss is : tensor(5.4177e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008811533815968128
now it is 29050 steps  and the cls_loss is : tensor(3.1841e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008715321431814267
now it is 29100 steps  and the cls_loss is : tensor(3.3328e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008619421664928023
now it is 29150 steps  and the cls_loss is : tensor(2.7319e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008523839285514687
now it is 29200 steps  and the cls_loss is : tensor(1.6015e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008428579047992198
now it is 29250 steps  and the cls_loss is : tensor(1.3949e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008333645690754649
now it is 29300 steps  and the cls_loss is : tensor(1.0668e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008239043935936583
now it is 29350 steps  and the cls_loss is : tensor(1.1880e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008144778489178126
now it is 29400 steps  and the cls_loss is : tensor(8.9125e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008050854039390916
now it is 29450 steps  and the cls_loss is : tensor(8.6241e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007957275258524858
now it is 29500 steps  and the cls_loss is : tensor(7.5030e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007864046801335741
now it is 29550 steps  and the cls_loss is : tensor(4.8933e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007771173305153711
now it is 29600 steps  and the cls_loss is : tensor(3.0485e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007678659389652584
now it is 29650 steps  and the cls_loss is : tensor(2.7865e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000758650965662008
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.004208822832315185
generate label finished(16.47/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 29700 steps  and the cls_loss is : tensor(2.3286e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007494728689728891
now it is 29750 steps  and the cls_loss is : tensor(1.8557e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007403321054308723
now it is 29800 steps  and the cls_loss is : tensor(1.1806e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007312291297119169
now it is 29850 steps  and the cls_loss is : tensor(1.0043e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007221643946123582
now it is 29900 steps  and the cls_loss is : tensor(8.5619e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131383510263809
now it is 29950 steps  and the cls_loss is : tensor(8.1653e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007041514479235943
now it is 30000 steps  and the cls_loss is : tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006952041323266989
now it is 30050 steps  and the cls_loss is : tensor(2.4547e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006862968492892477
now it is 30100 steps  and the cls_loss is : tensor(3.4675e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006774300418735153
now it is 30150 steps  and the cls_loss is : tensor(3.5302e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006686041511284519
now it is 30200 steps  and the cls_loss is : tensor(2.9882e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006598196160677502
now it is 30250 steps  and the cls_loss is : tensor(4.7166e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000651076873648004
now it is 30300 steps  and the cls_loss is : tensor(4.3057e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006423763587469768
now it is 30350 steps  and the cls_loss is : tensor(6.5171e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006337185041419691
now it is 30400 steps  and the cls_loss is : tensor(3.8542e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006251037404882908
now it is 30450 steps  and the cls_loss is : tensor(3.7464e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006165324962978392
now it is 30500 steps  and the cls_loss is : tensor(6.2507e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006080051979177861
now it is 30550 steps  and the cls_loss is : tensor(4.0040e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005995222695093695
now it is 30600 steps  and the cls_loss is : tensor(5.5858e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005910841330267945
now it is 30650 steps  and the cls_loss is : tensor(6.4396e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005826912081962462
now it is 30700 steps  and the cls_loss is : tensor(4.1553e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005743439124950105
now it is 30750 steps  and the cls_loss is : tensor(3.9882e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005660426611307083
now it is 30800 steps  and the cls_loss is : tensor(6.0821e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005577878670206443
now it is 30850 steps  and the cls_loss is : tensor(6.7282e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005495799407712635
now it is 30900 steps  and the cls_loss is : tensor(4.5913e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005414192906577322
now it is 30950 steps  and the cls_loss is : tensor(6.5269e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005333063226036269
now it is 31000 steps  and the cls_loss is : tensor(5.8841e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005252414401607419
now it is 31050 steps  and the cls_loss is : tensor(4.9717e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005172250444890195
now it is 31100 steps  and the cls_loss is : tensor(6.6545e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005092575343365929
now it is 31150 steps  and the cls_loss is : tensor(4.1660e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005013393060199524
now it is 31200 steps  and the cls_loss is : tensor(5.8403e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004934707534042326
now it is 31250 steps  and the cls_loss is : tensor(5.4119e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00048565226788362055
now it is 31300 steps  and the cls_loss is : tensor(6.5466e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047788423836188723
now it is 31350 steps  and the cls_loss is : tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047016705123304305
now it is 31400 steps  and the cls_loss is : tensor(7.8099e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004625010903621166
now it is 31450 steps  and the cls_loss is : tensor(8.3306e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045488673706606356
now it is 31500 steps  and the cls_loss is : tensor(6.4614e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044732437009479647
now it is 31550 steps  and the cls_loss is : tensor(1.1559e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043981436561234716
now it is 31600 steps  and the cls_loss is : tensor(8.2984e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004323570971781535
now it is 31650 steps  and the cls_loss is : tensor(8.2298e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042495293572848063
now it is 31700 steps  and the cls_loss is : tensor(8.3686e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041760224955796836
now it is 31750 steps  and the cls_loss is : tensor(7.3640e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041030540430131174
now it is 31800 steps  and the cls_loss is : tensor(6.7148e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004030627629150745
now it is 31850 steps  and the cls_loss is : tensor(6.8990e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003958746856596342
now it is 31900 steps  and the cls_loss is : tensor(6.7417e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003887415300812632
now it is 31950 steps  and the cls_loss is : tensor(6.9050e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003816636509943418
now it is 32000 steps  and the cls_loss is : tensor(9.5414e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037464140046371226
now it is 32050 steps  and the cls_loss is : tensor(8.0715e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036767512778716456
now it is 32100 steps  and the cls_loss is : tensor(9.4585e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000360765179478062
now it is 32150 steps  and the cls_loss is : tensor(7.8789e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003539118992481045
now it is 32200 steps  and the cls_loss is : tensor(1.0153e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034711562799023344
now it is 32250 steps  and the cls_loss is : tensor(8.5245e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003403767037616744
now it is 32300 steps  and the cls_loss is : tensor(6.8789e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003336954617671207
now it is 32350 steps  and the cls_loss is : tensor(6.9765e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032707223434206125
now it is 32400 steps  and the cls_loss is : tensor(5.0631e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003205073509362486
now it is 32450 steps  and the cls_loss is : tensor(5.7522e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031400113809731213
now it is 32500 steps  and the cls_loss is : tensor(5.6149e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030755391945451547
now it is 32550 steps  and the cls_loss is : tensor(5.4059e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030116601570265674
now it is 32600 steps  and the cls_loss is : tensor(3.8186e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00029483774458611905
now it is 32650 steps  and the cls_loss is : tensor(4.7316e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00028856942088306486
now it is 32700 steps  and the cls_loss is : tensor(4.1728e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00028236135638977654
now it is 32750 steps  and the cls_loss is : tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027621385990514956
now it is 32800 steps  and the cls_loss is : tensor(1.1541e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027012723721533147
now it is 32850 steps  and the cls_loss is : tensor(1.2681e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00026410179107851095
now it is 32900 steps  and the cls_loss is : tensor(1.7837e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00025813782120985893
now it is 32950 steps  and the cls_loss is : tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002522356242666201
now it is 33000 steps  and the cls_loss is : tensor(4.4266e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002463954938333564
now it is 33050 steps  and the cls_loss is : tensor(3.9798e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00024061772040734453
now it is 33100 steps  and the cls_loss is : tensor(5.0190e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00023490259138412453
now it is 33150 steps  and the cls_loss is : tensor(5.4729e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022925039104320586
now it is 33200 steps  and the cls_loss is : tensor(5.3011e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022366140053392653
now it is 33250 steps  and the cls_loss is : tensor(4.7919e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00021813589786146817
now it is 33300 steps  and the cls_loss is : tensor(4.6180e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002126741578730265
now it is 33350 steps  and the cls_loss is : tensor(4.5634e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00020727645224414198
now it is 33400 steps  and the cls_loss is : tensor(4.8917e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000201943049465185
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0029245510877912747
generate label finished(15.63/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 33450 steps  and the cls_loss is : tensor(4.4693e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00019667421482800105
now it is 33500 steps  and the cls_loss is : tensor(5.7302e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001914702104127145
now it is 33550 steps  and the cls_loss is : tensor(3.9846e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001863312950746929
now it is 33600 steps  and the cls_loss is : tensor(5.1315e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00018125772443167067
now it is 33650 steps  and the cls_loss is : tensor(3.3954e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017624975085103316
now it is 33700 steps  and the cls_loss is : tensor(4.3745e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017130762343726602
now it is 33750 steps  and the cls_loss is : tensor(3.8450e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016643158801956255
now it is 33800 steps  and the cls_loss is : tensor(3.4995e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016162188713959595
now it is 33850 steps  and the cls_loss is : tensor(3.2484e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001568787600394552
now it is 33900 steps  and the cls_loss is : tensor(3.3428e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00015220244264974473
now it is 33950 steps  and the cls_loss is : tensor(3.1200e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014759316757784893
now it is 34000 steps  and the cls_loss is : tensor(2.1434e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014305116409636215
now it is 34050 steps  and the cls_loss is : tensor(1.9844e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001385766581316833
now it is 34100 steps  and the cls_loss is : tensor(1.5927e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013416987225277913
now it is 34150 steps  and the cls_loss is : tensor(1.1797e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012983102566011255
now it is 34200 steps  and the cls_loss is : tensor(1.7523e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012556033417473997
now it is 34250 steps  and the cls_loss is : tensor(1.2954e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012135801022757427
now it is 34300 steps  and the cls_loss is : tensor(1.0532e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011722426284882088
now it is 34350 steps  and the cls_loss is : tensor(9.3649e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011315929765757833
now it is 34400 steps  and the cls_loss is : tensor(9.7233e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010916331685161015
now it is 34450 steps  and the cls_loss is : tensor(6.3684e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010523651919728913
now it is 34500 steps  and the cls_loss is : tensor(3.3375e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010137910001970857
now it is 34550 steps  and the cls_loss is : tensor(4.1616e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.759125119296731e-05
now it is 34600 steps  and the cls_loss is : tensor(4.6396e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.38731611306259e-05
now it is 34650 steps  and the cls_loss is : tensor(4.0149e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.022501477633357e-05
now it is 34700 steps  and the cls_loss is : tensor(2.2202e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.664699359462985e-05
now it is 34750 steps  and the cls_loss is : tensor(2.9938e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.313927556191804e-05
now it is 34800 steps  and the cls_loss is : tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.970203515761136e-05
now it is 34850 steps  and the cls_loss is : tensor(2.5427e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.633544335545568e-05
now it is 34900 steps  and the cls_loss is : tensor(3.2478e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.303966761502402e-05
now it is 34950 steps  and the cls_loss is : tensor(3.1263e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.981487187338738e-05
now it is 35000 steps  and the cls_loss is : tensor(3.3062e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.666121653695912e-05
now it is 35050 steps  and the cls_loss is : tensor(3.0021e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.357885847351755e-05
now it is 35100 steps  and the cls_loss is : tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.0567951004402545e-05
now it is 35150 steps  and the cls_loss is : tensor(3.4047e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.762864389688876e-05
now it is 35200 steps  and the cls_loss is : tensor(4.1877e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.476108335673623e-05
now it is 35250 steps  and the cls_loss is : tensor(3.6432e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.1965412020917724e-05
now it is 35300 steps  and the cls_loss is : tensor(4.3433e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.924176895052436e-05
now it is 35350 steps  and the cls_loss is : tensor(3.4768e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.659028962384736e-05
now it is 35400 steps  and the cls_loss is : tensor(5.1104e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.401110592964e-05
now it is 35450 steps  and the cls_loss is : tensor(2.8448e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.150434616055743e-05
now it is 35500 steps  and the cls_loss is : tensor(5.4503e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.90701350067745e-05
now it is 35550 steps  and the cls_loss is : tensor(4.3255e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.670859354978365e-05
now it is 35600 steps  and the cls_loss is : tensor(3.9899e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.441983925637273e-05
now it is 35650 steps  and the cls_loss is : tensor(5.1558e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.2203985972780956e-05
now it is 35700 steps  and the cls_loss is : tensor(4.3353e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.006114391903713e-05
now it is 35750 steps  and the cls_loss is : tensor(4.6744e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.7991419683476428e-05
now it is 35800 steps  and the cls_loss is : tensor(4.1728e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.5994916217438678e-05
now it is 35850 steps  and the cls_loss is : tensor(5.8425e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.4071732830147528e-05
now it is 35900 steps  and the cls_loss is : tensor(3.8525e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.2221965183770435e-05
now it is 35950 steps  and the cls_loss is : tensor(4.7763e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.0445705288660185e-05
now it is 36000 steps  and the cls_loss is : tensor(3.4854e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.874304149877894e-05
now it is 36050 steps  and the cls_loss is : tensor(3.9605e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.7114058507302463e-05
now it is 36100 steps  and the cls_loss is : tensor(3.7405e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.555883734240735e-05
now it is 36150 steps  and the cls_loss is : tensor(4.4564e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.4077455363241644e-05
now it is 36200 steps  and the cls_loss is : tensor(4.4703e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.2669986256075445e-05
now it is 36250 steps  and the cls_loss is : tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.1336500030636549e-05
now it is 36300 steps  and the cls_loss is : tensor(5.3200e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0077063016628093e-05
now it is 36350 steps  and the cls_loss is : tensor(4.3025e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.891737860428403e-06
now it is 36400 steps  and the cls_loss is : tensor(4.6826e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.780583521975846e-06
now it is 36450 steps  and the cls_loss is : tensor(5.0929e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.7436552718353765e-06
now it is 36500 steps  and the cls_loss is : tensor(4.1850e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.781004688449589e-06
now it is 36550 steps  and the cls_loss is : tensor(3.4473e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.892679655573137e-06
now it is 36600 steps  and the cls_loss is : tensor(5.4318e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.078724359890492e-06
now it is 36650 steps  and the cls_loss is : tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.339179288819221e-06
now it is 36700 steps  and the cls_loss is : tensor(3.7020e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.6740812284941248e-06
now it is 36750 steps  and the cls_loss is : tensor(4.0497e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.083463261939546e-06
now it is 36800 steps  and the cls_loss is : tensor(4.7946e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.567354767422205e-06
now it is 36850 steps  and the cls_loss is : tensor(4.2444e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.1257814169908837e-06
now it is 36900 steps  and the cls_loss is : tensor(4.0331e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.587651751984601e-07
now it is 36950 steps  and the cls_loss is : tensor(3.5630e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.6632429801029096e-07
now it is 37000 steps  and the cls_loss is : tensor(3.7317e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.484733318959494e-07
now it is 37050 steps  and the cls_loss is : tensor(4.8961e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0522311310497719e-07
now it is 37100 steps  and the cls_loss is : tensor(4.2211e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.6580767128653965e-08
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.003308838841252179
generate label finished(15.97/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

model: {
  second: {
    voxel_generator {
      point_cloud_range : [0, -40, -3, 70.4, 40, 1]
      #point_cloud_range: [0, -96.0, -20, 96.0, 96.0, 20]
      # point_cloud_range : [0, -32.0, -3, 52.8, 32.0, 1]
      #voxel_size : [0.2, 0.2, 1.0]   # original is 0.05,0.05,0.1
      voxel_size : [0.05, 0.05, 0.1]   # original is 0.05,0.05,0.1
      max_number_of_points_per_voxel : 5   # original is 5
    }

    voxel_feature_extractor: {
      module_class_name: "VoxelFeatureExtractorV3"
      num_filters: [16]
      with_distance: false
      num_input_features: 4
    }
    middle_feature_extractor: {
      module_class_name: "SpMiddleFHD"
      # num_filters_down1: [] # protobuf don't support empty list.
      # num_filters_down2: []
      downsample_factor: 8
      num_input_features: 4
    }
    rpn: {
      module_class_name: "RPNV2"
      layer_nums: [5, 5]
      layer_strides: [1, 2]
      num_filters: [128, 256]
      upsample_strides: [1, 2]
      num_upsample_filters: [256, 256]
      use_groupnorm: false
      num_groups: 32
      num_input_features: 128
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0   #original 1.0
      localization_weight: 2.0
    }
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true # this can help for orientation benchmark
    direction_loss_weight: 0.2 # enough.
    use_aux_classifier: false
    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    #post_center_limit_range: [0, -96.0, -20, 96.0, 96.0, 0]
    post_center_limit_range: [0, -40, -3.0, 70.4, 40, 0.0]
    use_rotate_nms: true
    use_multi_class_nms: false
    nms_pre_max_size: 1000
    nms_post_max_size: 100
    nms_score_threshold: 0.2
    nms_iou_threshold: 0.01

    use_bev: false
    num_point_features: 4
    without_reflectivity: false
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      anchor_generators: {
        anchor_generator_range: {
          sizes: [1.6, 3.9, 1.56] # wlh
          anchor_ranges: [0, -40.0, -1.78, 70.4, 40.0, -1.78] # carefully set z center, the original one is -1.78
          rotations: [0, 1.57] # DON'T modify this unless you are very familiar with my code.
          matched_threshold : 0.6
          unmatched_threshold : 0.45
          class_name: "Car"
        }
      }
      sample_positive_fraction : -1
      sample_size : 512
      region_similarity_calculator: {
        nearest_iou_similarity: {
        }
      }
    }
  }
}


train_input_reader: {
  max_num_epochs : 160
  batch_size: 1
  prefetch_size : 25
  max_number_of_voxels: 16000 # to support batchsize=2 in 1080Ti, original 16000
  shuffle_points: true
  num_workers: 3
  groundtruth_localization_noise_std: [1.0, 1.0, 0.5]
  # groundtruth_rotation_uniform_noise: [-0.3141592654, 0.3141592654]
  # groundtruth_rotation_uniform_noise: [-1.57, 1.57]
  groundtruth_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_scaling_uniform_noise: [0.95, 1.05]
  global_random_rotation_range_per_object: [0, 0] # pi/4 ~ 3pi/4
  anchor_area_threshold: -1
  remove_points_after_sample: true
  groundtruth_points_drop_percentage: 0.0
  groundtruth_drop_max_keep_points: 15
  database_sampler {
    database_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_dbinfos_train.pkl"
    sample_groups {
      name_to_max_num {
        key: "Car"
        value: 15
      }
    }
    database_prep_steps {
      filter_by_min_num_points {
        min_num_point_pairs {
          key: "Car"
          value: 5
        }
      }
    }
    database_prep_steps {
      filter_by_difficulty {
        removed_difficulties: [-1]
      }
    }
    global_random_rotation_range_per_object: [0, 0]
    rate: 1.0
  }

  remove_unknown_examples: false
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_train.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

train_config: {
  optimizer: {
    adam_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3  # original 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0  #original 10
          pct_start: 0.4
        }
      }
      weight_decay: 0.01 # super converge. decrease this when you increase steps. og 0.01
    }
    fixed_weight_decay: true
    use_moving_average: false
  }
  steps: 37120 #112215 #113715 #111360 # 619 * 50, super converge. increase this to achieve slightly better results original 30950
  steps_per_eval: 3712 #7481 # 619 * 5
  save_checkpoints_secs : 1800 # half hour 1800
  save_summary_steps : 10
  enable_mixed_precision: false # for fp16 training, don't use this.
  loss_scale_factor : 512.0
  clear_metrics_every_epoch: true
  detection_2d_path: "../d2_detection_data"
}

eval_input_reader: {
  batch_size: 1
  max_num_epochs : 160
  prefetch_size : 25
  max_number_of_voxels: 16000
  shuffle_points: false
  num_workers: 3
  anchor_area_threshold: -1
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_val.pkl"
  #kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original/data/kitti/kitti_infos_test.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

now it is 50 steps  and the cls_loss is : tensor(2904.2026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003000725556911313
now it is 100 steps  and the cls_loss is : tensor(577.7350, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300296159683897
now it is 150 steps  and the cls_loss is : tensor(262.4777, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003006708197788306
now it is 200 steps  and the cls_loss is : tensor(182.5569, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003011964940447371
now it is 250 steps  and the cls_loss is : tensor(116.8288, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003018731236492261
now it is 300 steps  and the cls_loss is : tensor(60.7894, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003027006328652909
now it is 350 steps  and the cls_loss is : tensor(41.8823, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003036789290797896
now it is 400 steps  and the cls_loss is : tensor(25.0605, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003048079028038046
now it is 450 steps  and the cls_loss is : tensor(11.1433, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030608742768490054
now it is 500 steps  and the cls_loss is : tensor(7.0821, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003075173605212619
now it is 550 steps  and the cls_loss is : tensor(5.0375, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003090975412777231
now it is 600 steps  and the cls_loss is : tensor(3.1848, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000310827793103677
now it is 650 steps  and the cls_loss is : tensor(2.5886, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031270792235286874
now it is 700 steps  and the cls_loss is : tensor(1.3303, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003147377186050681
now it is 750 steps  and the cls_loss is : tensor(1.0075, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031691695468961945
now it is 800 steps  and the cls_loss is : tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031924538671086484
now it is 850 steps  and the cls_loss is : tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003217227540754427
now it is 900 steps  and the cls_loss is : tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003243487795214512
now it is 950 steps  and the cls_loss is : tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032712316914947906
now it is 1000 steps  and the cls_loss is : tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003300456124554988
now it is 1050 steps  and the cls_loss is : tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003331157823656169
now it is 1100 steps  and the cls_loss is : tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033633333527267927
now it is 1150 steps  and the cls_loss is : tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033969791107472903
now it is 1200 steps  and the cls_loss is : tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003432091332153048
now it is 1250 steps  and the cls_loss is : tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003468666087255885
now it is 1300 steps  and the cls_loss is : tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035066992826837977
now it is 1350 steps  and the cls_loss is : tensor(0.0254, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035461866618391544
now it is 1400 steps  and the cls_loss is : tensor(0.0239, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003587123805375023
now it is 1450 steps  and the cls_loss is : tensor(0.0140, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003629506131689812
now it is 1500 steps  and the cls_loss is : tensor(0.0085, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003673328897440013
now it is 1550 steps  and the cls_loss is : tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003718587198071068
now it is 1600 steps  and the cls_loss is : tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037652759683663023
now it is 1650 steps  and the cls_loss is : tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003813389983013779
now it is 1700 steps  and the cls_loss is : tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003862923857191132
now it is 1750 steps  and the cls_loss is : tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003913872047168203
now it is 1800 steps  and the cls_loss is : tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003966228850927501
now it is 1850 steps  and the cls_loss is : tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040199884088023413
now it is 1900 steps  and the cls_loss is : tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040751447041326855
now it is 1950 steps  and the cls_loss is : tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041316915639384635
now it is 2000 steps  and the cls_loss is : tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004189622659610476
now it is 2050 steps  and the cls_loss is : tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042489315076186694
now it is 2100 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043096114702377607
now it is 2150 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043716557562901125
now it is 2200 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044350574219057925
now it is 2250 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004499809371299713
now it is 2300 steps  and the cls_loss is : tensor(7.6507e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045659043575657903
now it is 2350 steps  and the cls_loss is : tensor(5.3155e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00046333349834879866
now it is 2400 steps  and the cls_loss is : tensor(4.6925e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047020937023682
now it is 2450 steps  and the cls_loss is : tensor(3.9561e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004772172818870873
now it is 2500 steps  and the cls_loss is : tensor(2.6168e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00048435644898842415
now it is 2550 steps  and the cls_loss is : tensor(2.1039e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004916260725398116
now it is 2600 steps  and the cls_loss is : tensor(1.4238e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004990253389398113
now it is 2650 steps  and the cls_loss is : tensor(1.0907e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005065534200776206
now it is 2700 steps  and the cls_loss is : tensor(1.0549e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005142094734257559
now it is 2750 steps  and the cls_loss is : tensor(6.7421e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005219926421343433
now it is 2800 steps  and the cls_loss is : tensor(4.9281e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005299020551270185
now it is 2850 steps  and the cls_loss is : tensor(3.8706e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005379368271984128
now it is 2900 steps  and the cls_loss is : tensor(3.1585e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005460960591132263
now it is 2950 steps  and the cls_loss is : tensor(2.4385e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005543788377068678
now it is 3000 steps  and the cls_loss is : tensor(1.8437e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005627842359876515
now it is 3050 steps  and the cls_loss is : tensor(1.3540e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005713113132405499
now it is 3100 steps  and the cls_loss is : tensor(1.0941e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005799591151324696
now it is 3150 steps  and the cls_loss is : tensor(7.9422e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005887266738190643
now it is 3200 steps  and the cls_loss is : tensor(5.7923e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005976130080530494
now it is 3250 steps  and the cls_loss is : tensor(4.8617e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006066171232940259
now it is 3300 steps  and the cls_loss is : tensor(4.7716e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006157380118197828
now it is 3350 steps  and the cls_loss is : tensor(2.8267e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006249746528390822
now it is 3400 steps  and the cls_loss is : tensor(2.2479e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006343260126059026
now it is 3450 steps  and the cls_loss is : tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006437910445351355
now it is 3500 steps  and the cls_loss is : tensor(3.9324e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006533686893197138
now it is 3550 steps  and the cls_loss is : tensor(5.8669e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000663057875049171
now it is 3600 steps  and the cls_loss is : tensor(5.3742e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006728575173296052
now it is 3650 steps  and the cls_loss is : tensor(4.7838e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006827665194050424
now it is 3700 steps  and the cls_loss is : tensor(4.6917e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000692783772280184
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.003395173943004577
generate label finished(24.40/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 3750 steps  and the cls_loss is : tensor(4.0740e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007029081548445221
now it is 3800 steps  and the cls_loss is : tensor(3.5860e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131385339978124
now it is 3850 steps  and the cls_loss is : tensor(3.2126e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000723473764776889
now it is 3900 steps  and the cls_loss is : tensor(2.6500e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007339126904838062
now it is 3950 steps  and the cls_loss is : tensor(1.5435e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007444541428152933
now it is 4000 steps  and the cls_loss is : tensor(1.1673e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007550969419935082
now it is 4050 steps  and the cls_loss is : tensor(6.5038e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000765839896898077
now it is 4100 steps  and the cls_loss is : tensor(4.0518e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007766818051994011
now it is 4150 steps  and the cls_loss is : tensor(2.8306e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007876214534932205
now it is 4200 steps  and the cls_loss is : tensor(2.0610e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007986576174364136
now it is 4250 steps  and the cls_loss is : tensor(1.5037e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008097890618840231
now it is 4300 steps  and the cls_loss is : tensor(9.8711e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008210145410274955
now it is 4350 steps  and the cls_loss is : tensor(5.9106e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008323327985341024
now it is 4400 steps  and the cls_loss is : tensor(5.3734e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008437425676875517
now it is 4450 steps  and the cls_loss is : tensor(4.2808e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008552425715297549
now it is 4500 steps  and the cls_loss is : tensor(2.3766e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008668315230037403
now it is 4550 steps  and the cls_loss is : tensor(1.8470e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008785081250976996
now it is 4600 steps  and the cls_loss is : tensor(1.4979e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008902710709901445
now it is 4650 steps  and the cls_loss is : tensor(1.3056e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000902119044196167
now it is 4700 steps  and the cls_loss is : tensor(8.9594e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009140507187147739
now it is 4750 steps  and the cls_loss is : tensor(6.5676e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009260647591772921
now it is 4800 steps  and the cls_loss is : tensor(0.0444, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009381598209968205
now it is 4850 steps  and the cls_loss is : tensor(1.1360e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009503345505187132
now it is 4900 steps  and the cls_loss is : tensor(1.4482e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000962587585172077
now it is 4950 steps  and the cls_loss is : tensor(1.6520e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009749175536222683
now it is 5000 steps  and the cls_loss is : tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009873230759243697
now it is 5050 steps  and the cls_loss is : tensor(9.3364e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009998027636776313
now it is 5100 steps  and the cls_loss is : tensor(4.3637e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001012355220180857
now it is 5150 steps  and the cls_loss is : tensor(1.3137e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010249790405887204
now it is 5200 steps  and the cls_loss is : tensor(4.5129e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010376728120689927
now it is 5250 steps  and the cls_loss is : tensor(2.9160e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010504351139606636
now it is 5300 steps  and the cls_loss is : tensor(2.0079e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010632645179329393
now it is 5350 steps  and the cls_loss is : tensor(1.2019e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010761595881450979
now it is 5400 steps  and the cls_loss is : tensor(8.8735e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010891188814071855
now it is 5450 steps  and the cls_loss is : tensor(5.6112e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011021409473415357
now it is 5500 steps  and the cls_loss is : tensor(3.9870e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011152243285450926
now it is 5550 steps  and the cls_loss is : tensor(2.9575e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001128367560752521
now it is 5600 steps  and the cls_loss is : tensor(2.1675e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011415691730000822
now it is 5650 steps  and the cls_loss is : tensor(1.4434e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011548276877902644
now it is 5700 steps  and the cls_loss is : tensor(1.2241e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011681416212571375
now it is 5750 steps  and the cls_loss is : tensor(8.1621e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011815094833324265
now it is 5800 steps  and the cls_loss is : tensor(6.5543e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011949297779122777
now it is 5850 steps  and the cls_loss is : tensor(5.2659e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001208401003024697
now it is 5900 steps  and the cls_loss is : tensor(3.7307e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00122192165099765
now it is 5950 steps  and the cls_loss is : tensor(3.0859e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012354902086277964
now it is 6000 steps  and the cls_loss is : tensor(2.2081e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012491051573498436
now it is 6050 steps  and the cls_loss is : tensor(1.6220e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012627649734065047
now it is 6100 steps  and the cls_loss is : tensor(1.3733e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012764681280190307
now it is 6150 steps  and the cls_loss is : tensor(9.9344e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012902130875583106
now it is 6200 steps  and the cls_loss is : tensor(8.4989e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013039983137165102
now it is 6250 steps  and the cls_loss is : tensor(6.0297e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013178222636792386
now it is 6300 steps  and the cls_loss is : tensor(4.7518e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013316833902982158
now it is 6350 steps  and the cls_loss is : tensor(3.9704e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013455801422644254
now it is 6400 steps  and the cls_loss is : tensor(2.7643e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013595109642817347
now it is 6450 steps  and the cls_loss is : tensor(2.2614e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013734742972409612
now it is 6500 steps  and the cls_loss is : tensor(1.7843e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013874685783943645
now it is 6550 steps  and the cls_loss is : tensor(1.4967e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014014922415305432
now it is 6600 steps  and the cls_loss is : tensor(1.2595e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014155437171497274
now it is 6650 steps  and the cls_loss is : tensor(9.9521e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001429621432639428
now it is 6700 steps  and the cls_loss is : tensor(7.5878e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014437238124504453
now it is 6750 steps  and the cls_loss is : tensor(7.0726e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014578492782731974
now it is 6800 steps  and the cls_loss is : tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014719962492143641
now it is 6850 steps  and the cls_loss is : tensor(1.7757e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014861631419738161
now it is 6900 steps  and the cls_loss is : tensor(2.9242e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015003483710218147
now it is 6950 steps  and the cls_loss is : tensor(2.9784e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015145503487764605
now it is 7000 steps  and the cls_loss is : tensor(3.2272e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015287674857813742
now it is 7050 steps  and the cls_loss is : tensor(3.1468e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001542998190883584
now it is 7100 steps  and the cls_loss is : tensor(3.2757e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015572408714116033
now it is 7150 steps  and the cls_loss is : tensor(3.1620e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015714939333536806
now it is 7200 steps  and the cls_loss is : tensor(2.9066e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015857557815361987
now it is 7250 steps  and the cls_loss is : tensor(2.7886e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016000248198022014
now it is 7300 steps  and the cls_loss is : tensor(2.8718e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016142994511900328
now it is 7350 steps  and the cls_loss is : tensor(2.8114e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016285780781120677
now it is 7400 steps  and the cls_loss is : tensor(2.4546e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016428591025335066
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0033935786515394833
generate label finished(24.77/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 7450 steps  and the cls_loss is : tensor(2.0521e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016571409261512285
now it is 7500 steps  and the cls_loss is : tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016714219505726679
now it is 7550 steps  and the cls_loss is : tensor(0.0267, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001685700577494702
now it is 7600 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016999752088825337
now it is 7650 steps  and the cls_loss is : tensor(9.7737e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017142442471485364
now it is 7700 steps  and the cls_loss is : tensor(6.2271e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017285060953310543
now it is 7750 steps  and the cls_loss is : tensor(4.2902e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017427591572731318
now it is 7800 steps  and the cls_loss is : tensor(2.9473e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001757001837801151
now it is 7850 steps  and the cls_loss is : tensor(2.2719e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017712325429033603
now it is 7900 steps  and the cls_loss is : tensor(1.6905e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001785449679908274
now it is 7950 steps  and the cls_loss is : tensor(1.0679e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017996516576629206
now it is 8000 steps  and the cls_loss is : tensor(1.0532e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018138368867109188
now it is 8050 steps  and the cls_loss is : tensor(8.4641e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001828003779470371
now it is 8100 steps  and the cls_loss is : tensor(6.1065e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018421507504115377
now it is 8150 steps  and the cls_loss is : tensor(4.7737e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018562762162342898
now it is 8200 steps  and the cls_loss is : tensor(3.9415e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001870378596045307
now it is 8250 steps  and the cls_loss is : tensor(3.2135e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018844563115350077
now it is 8300 steps  and the cls_loss is : tensor(2.0970e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018985077871541912
now it is 8350 steps  and the cls_loss is : tensor(1.6405e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019125314502903706
now it is 8400 steps  and the cls_loss is : tensor(1.3344e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019265257314437737
now it is 8450 steps  and the cls_loss is : tensor(9.4383e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019404890644030006
now it is 8500 steps  and the cls_loss is : tensor(7.8634e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00195441988642031
now it is 8550 steps  and the cls_loss is : tensor(6.4834e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019683166383865193
now it is 8600 steps  and the cls_loss is : tensor(4.7716e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019821777650054963
now it is 8650 steps  and the cls_loss is : tensor(4.4405e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001996001714968225
now it is 8700 steps  and the cls_loss is : tensor(3.1184e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020097869411264246
now it is 8750 steps  and the cls_loss is : tensor(2.5135e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002023531900665704
now it is 8800 steps  and the cls_loss is : tensor(1.7387e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00203723505527823
now it is 8850 steps  and the cls_loss is : tensor(1.4973e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020508948713348907
now it is 8900 steps  and the cls_loss is : tensor(1.2436e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002064509820056939
now it is 8950 steps  and the cls_loss is : tensor(8.4129e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002078078377687085
now it is 9000 steps  and the cls_loss is : tensor(6.5963e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002091599025660038
now it is 9050 steps  and the cls_loss is : tensor(5.3304e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002105070250772457
now it is 9100 steps  and the cls_loss is : tensor(4.3458e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021184905453523082
now it is 9150 steps  and the cls_loss is : tensor(3.2721e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021318584074275977
now it is 9200 steps  and the cls_loss is : tensor(2.6891e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021451723408944705
now it is 9250 steps  and the cls_loss is : tensor(2.0738e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021584308556846523
now it is 9300 steps  and the cls_loss is : tensor(1.7449e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021716324679322144
now it is 9350 steps  and the cls_loss is : tensor(1.3674e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021847757001396424
now it is 9400 steps  and the cls_loss is : tensor(8.8340e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021978590813432
now it is 9450 steps  and the cls_loss is : tensor(8.2912e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00221088114727755
now it is 9500 steps  and the cls_loss is : tensor(6.3159e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022238404405396373
now it is 9550 steps  and the cls_loss is : tensor(5.1348e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022367355107517956
now it is 9600 steps  and the cls_loss is : tensor(3.8544e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002249564914724071
now it is 9650 steps  and the cls_loss is : tensor(2.7069e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022623272166157424
now it is 9700 steps  and the cls_loss is : tensor(2.4826e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022750209880960143
now it is 9750 steps  and the cls_loss is : tensor(2.1445e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022876448085038777
now it is 9800 steps  and the cls_loss is : tensor(1.3911e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023001972650071034
now it is 9850 steps  and the cls_loss is : tensor(1.2690e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023126769527603654
now it is 9900 steps  and the cls_loss is : tensor(9.7573e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002325082475062467
now it is 9950 steps  and the cls_loss is : tensor(7.1959e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023374124435126577
now it is 10000 steps  and the cls_loss is : tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023496654781660214
now it is 10050 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002361840207687914
now it is 10100 steps  and the cls_loss is : tensor(6.7225e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023739352695074426
now it is 10150 steps  and the cls_loss is : tensor(4.6079e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002385949309969961
now it is 10200 steps  and the cls_loss is : tensor(3.2589e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023978809844885677
now it is 10250 steps  and the cls_loss is : tensor(2.5871e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00240972895769459
now it is 10300 steps  and the cls_loss is : tensor(1.6566e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024214919035870355
now it is 10350 steps  and the cls_loss is : tensor(1.1367e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002433168505680995
now it is 10400 steps  and the cls_loss is : tensor(8.0659e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00244475745715498
now it is 10450 steps  and the cls_loss is : tensor(5.6843e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024562574609971835
now it is 10500 steps  and the cls_loss is : tensor(3.8423e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024676672301506327
now it is 10550 steps  and the cls_loss is : tensor(2.2204e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024789854876572396
now it is 10600 steps  and the cls_loss is : tensor(2.0801e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024902109668007116
now it is 10650 steps  and the cls_loss is : tensor(1.4515e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025013424112483216
now it is 10700 steps  and the cls_loss is : tensor(1.0215e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025123785751915142
now it is 10750 steps  and the cls_loss is : tensor(6.2821e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025233182234853336
now it is 10800 steps  and the cls_loss is : tensor(5.0202e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025341601317866577
now it is 10850 steps  and the cls_loss is : tensor(3.4933e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025449030866912274
now it is 10900 steps  and the cls_loss is : tensor(2.3281e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002555545885869442
now it is 10950 steps  and the cls_loss is : tensor(1.7375e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025660873382009285
now it is 11000 steps  and the cls_loss is : tensor(1.3214e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002576526263907846
now it is 11050 steps  and the cls_loss is : tensor(8.8256e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025868614946869223
now it is 11100 steps  and the cls_loss is : tensor(6.4743e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002597091873840213
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.00389522316521236
generate label finished(24.44/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 11150 steps  and the cls_loss is : tensor(4.5905e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002607216256404551
now it is 11200 steps  and the cls_loss is : tensor(3.3823e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026172335092796923
now it is 11250 steps  and the cls_loss is : tensor(2.3973e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00262714251135513
now it is 11300 steps  and the cls_loss is : tensor(2.1206e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002636942153635564
now it is 11350 steps  and the cls_loss is : tensor(1.7699e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026466313393650213
now it is 11400 steps  and the cls_loss is : tensor(1.2898e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026562089841495997
now it is 11450 steps  and the cls_loss is : tensor(9.1177e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002665674016078832
now it is 11500 steps  and the cls_loss is : tensor(7.6560e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026750253758456525
now it is 11550 steps  and the cls_loss is : tensor(5.6522e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002684262016864952
now it is 11600 steps  and the cls_loss is : tensor(4.1772e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002693382905390709
now it is 11650 steps  and the cls_loss is : tensor(3.2460e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027023870206316853
now it is 11700 steps  and the cls_loss is : tensor(2.5915e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002711273354865671
now it is 11750 steps  and the cls_loss is : tensor(2.0842e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002720040913552265
now it is 11800 steps  and the cls_loss is : tensor(1.7048e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027286887154441856
now it is 11850 steps  and the cls_loss is : tensor(1.2353e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002737215792697083
now it is 11900 steps  and the cls_loss is : tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027456211909778674
now it is 11950 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002753903969571509
now it is 12000 steps  and the cls_loss is : tensor(7.0785e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027620632014863223
now it is 12050 steps  and the cls_loss is : tensor(4.5147e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002770097973557717
now it is 12100 steps  and the cls_loss is : tensor(3.0868e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002778007386550392
now it is 12150 steps  and the cls_loss is : tensor(2.1798e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002785790555258979
now it is 12200 steps  and the cls_loss is : tensor(1.4880e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002793446608607114
now it is 12250 steps  and the cls_loss is : tensor(1.1052e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002800974689744924
now it is 12300 steps  and the cls_loss is : tensor(8.7312e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028083739561449235
now it is 12350 steps  and the cls_loss is : tensor(6.8256e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002815643579696311
now it is 12400 steps  and the cls_loss is : tensor(5.2886e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028227827467976474
now it is 12450 steps  and the cls_loss is : tensor(3.9209e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002829790658447915
now it is 12500 steps  and the cls_loss is : tensor(2.8618e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028366665303359365
now it is 12550 steps  and the cls_loss is : tensor(2.8540e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002843409592928156
now it is 12600 steps  and the cls_loss is : tensor(1.8163e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002850019091554764
now it is 12650 steps  and the cls_loss is : tensor(1.5584e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028564942864941563
now it is 12700 steps  and the cls_loss is : tensor(1.1384e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002862834453055724
now it is 12750 steps  and the cls_loss is : tensor(8.5995e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002869038881660959
now it is 12800 steps  and the cls_loss is : tensor(6.4561e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028751068779228678
now it is 12850 steps  and the cls_loss is : tensor(5.4951e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028810377627236875
now it is 12900 steps  and the cls_loss is : tensor(4.0001e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028868308722908888
now it is 12950 steps  and the cls_loss is : tensor(3.6957e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028924855582714666
now it is 13000 steps  and the cls_loss is : tensor(3.2493e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028980011878045006
now it is 13050 steps  and the cls_loss is : tensor(2.3268e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029033771435919855
now it is 13100 steps  and the cls_loss is : tensor(1.8936e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002908612823967915
now it is 13150 steps  and the cls_loss is : tensor(1.2782e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002913707642965622
now it is 13200 steps  and the cls_loss is : tensor(9.8778e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918661030383357
now it is 13250 steps  and the cls_loss is : tensor(8.9703e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002923472431848105
now it is 13300 steps  and the cls_loss is : tensor(5.9838e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029281413088776283
now it is 13350 steps  and the cls_loss is : tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029326671389407343
now it is 13400 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002937049415515754
now it is 13450 steps  and the cls_loss is : tensor(7.9344e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029412876481472324
now it is 13500 steps  and the cls_loss is : tensor(3.6020e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029453813625008192
now it is 13550 steps  and the cls_loss is : tensor(2.9392e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002949330100416355
now it is 13600 steps  and the cls_loss is : tensor(2.3247e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002953133419959147
now it is 13650 steps  and the cls_loss is : tensor(1.5586e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00295679089546943
now it is 13700 steps  and the cls_loss is : tensor(1.1438e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002960302117610006
now it is 13750 steps  and the cls_loss is : tensor(8.1767e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002963666693412056
now it is 13800 steps  and the cls_loss is : tensor(6.2644e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029668842463191182
now it is 13850 steps  and the cls_loss is : tensor(5.7077e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029699544162292363
now it is 13900 steps  and the cls_loss is : tensor(4.2661e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029728768595352556
now it is 13950 steps  and the cls_loss is : tensor(3.4067e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002975651249163284
now it is 14000 steps  and the cls_loss is : tensor(2.5691e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029782772746092924
now it is 14050 steps  and the cls_loss is : tensor(2.1593e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029807546419738703
now it is 14100 steps  and the cls_loss is : tensor(1.5788e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029830830739951157
now it is 14150 steps  and the cls_loss is : tensor(1.3839e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002985262310079667
now it is 14200 steps  and the cls_loss is : tensor(9.9363e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029872921063318664
now it is 14250 steps  and the cls_loss is : tensor(7.1284e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002989172235581058
now it is 14300 steps  and the cls_loss is : tensor(5.4057e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990902487407012
now it is 14350 steps  and the cls_loss is : tensor(4.0695e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002992482668163473
now it is 14400 steps  and the cls_loss is : tensor(3.5006e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029939126009998346
now it is 14450 steps  and the cls_loss is : tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00299519212588093
now it is 14500 steps  and the cls_loss is : tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029963210996049455
now it is 14550 steps  and the cls_loss is : tensor(5.9820e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997299395819444
now it is 14600 steps  and the cls_loss is : tensor(1.3325e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981269050355095
now it is 14650 steps  and the cls_loss is : tensor(6.9040e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998803534639998
now it is 14700 steps  and the cls_loss is : tensor(4.1237e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993292089059045
now it is 14750 steps  and the cls_loss is : tensor(2.8825e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029997038690008377
now it is 14800 steps  and the cls_loss is : tensor(2.3081e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999274729936042
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0035573450646114147
generate label finished(24.17/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 14850 steps  and the cls_loss is : tensor(1.6462e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.003000000011154647
now it is 14900 steps  and the cls_loss is : tensor(1.3204e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999961213121653
now it is 14950 steps  and the cls_loss is : tensor(8.4730e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998478054047454
now it is 15000 steps  and the cls_loss is : tensor(7.1468e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029996597936450026
now it is 15050 steps  and the cls_loss is : tensor(5.4311e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993971871944258
now it is 15100 steps  and the cls_loss is : tensor(3.4579e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029990599991154727
now it is 15150 steps  and the cls_loss is : tensor(2.6262e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998648246180409
now it is 15200 steps  and the cls_loss is : tensor(1.7165e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981619488704736
now it is 15250 steps  and the cls_loss is : tensor(1.3554e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997601131374859
now it is 15300 steps  and the cls_loss is : tensor(1.3520e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029969658215895107
now it is 15350 steps  and the cls_loss is : tensor(9.1833e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029962560511157367
now it is 15400 steps  and the cls_loss is : tensor(8.1727e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029954718552586378
now it is 15450 steps  and the cls_loss is : tensor(8.0133e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002994613273025348
now it is 15500 steps  and the cls_loss is : tensor(5.2155e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029936803471231
now it is 15550 steps  and the cls_loss is : tensor(3.2975e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029926731239570954
now it is 15600 steps  and the cls_loss is : tensor(2.7557e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029915916536281994
now it is 15650 steps  and the cls_loss is : tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990435989930447
now it is 15700 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029892061903483693
now it is 15750 steps  and the cls_loss is : tensor(2.0031e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029879023160541327
now it is 15800 steps  and the cls_loss is : tensor(5.0580e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002986524431904495
now it is 15850 steps  and the cls_loss is : tensor(3.8800e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029850726064375834
now it is 15900 steps  and the cls_loss is : tensor(1.6501e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002983546911869479
now it is 15950 steps  and the cls_loss is : tensor(1.4421e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029819474240906315
now it is 16000 steps  and the cls_loss is : tensor(1.0320e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002980274222662078
now it is 16050 steps  and the cls_loss is : tensor(5.4564e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029785273908114916
now it is 16100 steps  and the cls_loss is : tensor(4.3153e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029767070154290364
now it is 16150 steps  and the cls_loss is : tensor(4.2833e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029748131870630475
now it is 16200 steps  and the cls_loss is : tensor(2.8163e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002972845999915528
now it is 16250 steps  and the cls_loss is : tensor(2.1197e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029708055518374616
now it is 16300 steps  and the cls_loss is : tensor(1.7991e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029686919443239457
now it is 16350 steps  and the cls_loss is : tensor(1.1120e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029665052825091436
now it is 16400 steps  and the cls_loss is : tensor(1.0021e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029642456751610546
now it is 16450 steps  and the cls_loss is : tensor(6.5256e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029619132346761032
now it is 16500 steps  and the cls_loss is : tensor(6.2679e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002959508077073548
now it is 16550 steps  and the cls_loss is : tensor(3.4166e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029570303219897134
now it is 16600 steps  and the cls_loss is : tensor(3.9415e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029544800926720356
now it is 16650 steps  and the cls_loss is : tensor(2.9542e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029518575159729324
now it is 16700 steps  and the cls_loss is : tensor(2.0091e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029491627223434957
now it is 16750 steps  and the cls_loss is : tensor(1.9536e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002946395845827
now it is 16800 steps  and the cls_loss is : tensor(1.5538e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002943557024052237
now it is 16850 steps  and the cls_loss is : tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029406463982266672
now it is 16900 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029376641131293995
now it is 16950 steps  and the cls_loss is : tensor(5.9859e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002934610317103987
now it is 17000 steps  and the cls_loss is : tensor(8.6077e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002931485162051048
now it is 17050 steps  and the cls_loss is : tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029282888034207117
now it is 17100 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002925021400204885
now it is 17150 steps  and the cls_loss is : tensor(2.5188e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002921683114929346
now it is 17200 steps  and the cls_loss is : tensor(0.0270, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918274113645655
now it is 17250 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029147945659229006
now it is 17300 steps  and the cls_loss is : tensor(4.1047e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029112446448392604
now it is 17350 steps  and the cls_loss is : tensor(2.6494e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029076245269733935
now it is 17400 steps  and the cls_loss is : tensor(1.2358e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00290393439239566
now it is 17450 steps  and the cls_loss is : tensor(9.4990e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029001744246591587
now it is 17500 steps  and the cls_loss is : tensor(7.8450e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028963448107906004
now it is 17550 steps  and the cls_loss is : tensor(5.2330e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002892445741281004
now it is 17600 steps  and the cls_loss is : tensor(2.8640e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002888477410076222
now it is 17650 steps  and the cls_loss is : tensor(4.0751e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002884440014567292
now it is 17700 steps  and the cls_loss is : tensor(1.6879e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002880333755580618
now it is 17750 steps  and the cls_loss is : tensor(1.7219e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002876158837367984
now it is 17800 steps  and the cls_loss is : tensor(2.0670e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002871915467596389
now it is 17850 steps  and the cls_loss is : tensor(1.0113e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002867603857337723
now it is 17900 steps  and the cls_loss is : tensor(5.8922e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028632242210582626
now it is 17950 steps  and the cls_loss is : tensor(5.8450e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002858776776608008
now it is 18000 steps  and the cls_loss is : tensor(4.2883e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028542617452098425
now it is 18050 steps  and the cls_loss is : tensor(3.7300e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002849679351448532
now it is 18100 steps  and the cls_loss is : tensor(2.8549e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028450298232595523
now it is 18150 steps  and the cls_loss is : tensor(2.1652e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028403133919177505
now it is 18200 steps  and the cls_loss is : tensor(1.2090e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002835530292025842
now it is 18250 steps  and the cls_loss is : tensor(1.0802e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00283068076150274
now it is 18300 steps  and the cls_loss is : tensor(1.1110e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028257650415717244
now it is 18350 steps  and the cls_loss is : tensor(8.5227e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002820783376748438
now it is 18400 steps  and the cls_loss is : tensor(6.8519e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028157360148287256
now it is 18450 steps  and the cls_loss is : tensor(4.2920e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002810623206876312
now it is 18500 steps  and the cls_loss is : tensor(3.1610e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028054452072103085
now it is 18550 steps  and the cls_loss is : tensor(2.5073e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028002022733925646
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0038061509475827565
generate label finished(25.16/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 18600 steps  and the cls_loss is : tensor(2.0156e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002794894666214858
now it is 18650 steps  and the cls_loss is : tensor(1.6747e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00278952264968592
now it is 18700 steps  and the cls_loss is : tensor(1.4144e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002784086491018305
now it is 18750 steps  and the cls_loss is : tensor(1.1601e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027785864606150977
now it is 18800 steps  and the cls_loss is : tensor(7.9430e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002773022832056464
now it is 18850 steps  and the cls_loss is : tensor(6.8639e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027673958820860415
now it is 18900 steps  and the cls_loss is : tensor(4.1334e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002761705890597176
now it is 18950 steps  and the cls_loss is : tensor(3.9786e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002755953140618995
now it is 19000 steps  and the cls_loss is : tensor(3.6492e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027501379183023336
now it is 19050 steps  and the cls_loss is : tensor(2.9822e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027442605129055003
now it is 19100 steps  and the cls_loss is : tensor(1.9772e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027383212167798854
now it is 19150 steps  and the cls_loss is : tensor(1.8497e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027323203253554235
now it is 19200 steps  and the cls_loss is : tensor(1.3868e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027262581371258953
now it is 19250 steps  and the cls_loss is : tensor(1.1969e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002720134953634081
now it is 19300 steps  and the cls_loss is : tensor(8.2181e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002713951079456761
now it is 19350 steps  and the cls_loss is : tensor(6.7604e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002707706822189567
now it is 19400 steps  and the cls_loss is : tensor(6.0313e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002701402492431679
now it is 19450 steps  and the cls_loss is : tensor(4.7390e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002695038403770379
now it is 19500 steps  and the cls_loss is : tensor(3.8048e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002688614872765449
now it is 19550 steps  and the cls_loss is : tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026821322189334276
now it is 19600 steps  and the cls_loss is : tensor(3.0323e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026755907647317166
now it is 19650 steps  and the cls_loss is : tensor(8.9629e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002668990835542539
now it is 19700 steps  and the cls_loss is : tensor(2.2372e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026623327596567567
now it is 19750 steps  and the cls_loss is : tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00265561686825754
now it is 19800 steps  and the cls_loss is : tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002648843495403894
now it is 19850 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002642012978014039
now it is 19900 steps  and the cls_loss is : tensor(6.0419e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00263512565584866
now it is 19950 steps  and the cls_loss is : tensor(3.4463e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002628181871493995
now it is 20000 steps  and the cls_loss is : tensor(3.8118e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002621181970344804
now it is 20050 steps  and the cls_loss is : tensor(1.8144e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026141263005871824
now it is 20100 steps  and the cls_loss is : tensor(1.0898e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026070152131812455
now it is 20150 steps  and the cls_loss is : tensor(1.2740e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025998490618436695
now it is 20200 steps  and the cls_loss is : tensor(8.0682e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025926282030300954
now it is 20250 steps  and the cls_loss is : tensor(6.5229e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002585352995917402
now it is 20300 steps  and the cls_loss is : tensor(4.2691e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025780238023858384
now it is 20350 steps  and the cls_loss is : tensor(3.9541e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002570640987001021
now it is 20400 steps  and the cls_loss is : tensor(3.7116e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002563204916995803
now it is 20450 steps  and the cls_loss is : tensor(1.8947e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025557159622520064
now it is 20500 steps  and the cls_loss is : tensor(1.8758e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002548174495282022
now it is 20550 steps  and the cls_loss is : tensor(1.0904e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025405808912102824
now it is 20600 steps  and the cls_loss is : tensor(8.7842e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002532935527754602
now it is 20650 steps  and the cls_loss is : tensor(7.9698e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025252387852073865
now it is 20700 steps  and the cls_loss is : tensor(8.1793e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025174910464167213
now it is 20750 steps  and the cls_loss is : tensor(2.9230e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002509692696767323
now it is 20800 steps  and the cls_loss is : tensor(1.9584e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025018441241613726
now it is 20850 steps  and the cls_loss is : tensor(9.2878e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024939457189992196
now it is 20900 steps  and the cls_loss is : tensor(3.5155e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024859978741599647
now it is 20950 steps  and the cls_loss is : tensor(3.6181e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024780009849819135
now it is 21000 steps  and the cls_loss is : tensor(3.2117e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002469955449242916
now it is 21050 steps  and the cls_loss is : tensor(1.9809e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024618616671405785
now it is 21100 steps  and the cls_loss is : tensor(1.1879e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002453720041272357
now it is 21150 steps  and the cls_loss is : tensor(1.1198e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002445530976615532
now it is 21200 steps  and the cls_loss is : tensor(4.8238e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024372948805070627
now it is 21250 steps  and the cls_loss is : tensor(6.8696e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002429012162623329
now it is 21300 steps  and the cls_loss is : tensor(4.1309e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024206832349597486
now it is 21350 steps  and the cls_loss is : tensor(5.6498e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002412308511810288
now it is 21400 steps  and the cls_loss is : tensor(2.6376e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024038884097468535
now it is 21450 steps  and the cls_loss is : tensor(1.4509e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002395423347598569
now it is 21500 steps  and the cls_loss is : tensor(1.9895e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023869137464309445
now it is 21550 steps  and the cls_loss is : tensor(1.8123e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00237836002952493
now it is 21600 steps  and the cls_loss is : tensor(1.2634e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002369762622355863
now it is 21650 steps  and the cls_loss is : tensor(1.2941e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002361121952572302
now it is 21700 steps  and the cls_loss is : tensor(9.8794e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002352438449974757
now it is 21750 steps  and the cls_loss is : tensor(6.5360e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00234371254649431
now it is 21800 steps  and the cls_loss is : tensor(7.1746e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023349446761711276
now it is 21850 steps  and the cls_loss is : tensor(8.4748e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002326135275132875
now it is 21900 steps  and the cls_loss is : tensor(5.1005e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00231728478157302
now it is 21950 steps  and the cls_loss is : tensor(4.9076e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023083936357290377
now it is 22000 steps  and the cls_loss is : tensor(3.5621e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022994622798605106
now it is 22050 steps  and the cls_loss is : tensor(2.8830e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022904911582271315
now it is 22100 steps  and the cls_loss is : tensor(2.9890e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002281480717066605
now it is 22150 steps  and the cls_loss is : tensor(3.5281e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022724314045724516
now it is 22200 steps  and the cls_loss is : tensor(1.4860e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002263343670871711
now it is 22250 steps  and the cls_loss is : tensor(1.3767e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022542179680025572
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.004608091788909648
generate label finished(25.18/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 22300 steps  and the cls_loss is : tensor(2.1146e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022450547498918077
now it is 22350 steps  and the cls_loss is : tensor(1.3955e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002235854472332348
now it is 22400 steps  and the cls_loss is : tensor(1.0382e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00222661759296046
now it is 22450 steps  and the cls_loss is : tensor(1.1427e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002217344571233056
now it is 22500 steps  and the cls_loss is : tensor(2.1728e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002208035868404826
now it is 22550 steps  and the cls_loss is : tensor(1.0498e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021986919475052943
now it is 22600 steps  and the cls_loss is : tensor(3.7853e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021893132733157876
now it is 22650 steps  and the cls_loss is : tensor(8.5022e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002179900312346316
now it is 22700 steps  and the cls_loss is : tensor(6.3870e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021704535328123695
now it is 22750 steps  and the cls_loss is : tensor(2.4541e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002160973404611622
now it is 22800 steps  and the cls_loss is : tensor(4.2671e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021514603993005683
now it is 22850 steps  and the cls_loss is : tensor(4.1483e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021419149900710577
now it is 22900 steps  and the cls_loss is : tensor(2.8166e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021323376517267648
now it is 22950 steps  and the cls_loss is : tensor(2.4594e-11, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021227288606595674
now it is 23000 steps  and the cls_loss is : tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021130890948258497
now it is 23050 steps  and the cls_loss is : tensor(6.3354e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021034188337227325
now it is 23100 steps  and the cls_loss is : tensor(6.4551e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002093718558364216
now it is 23150 steps  and the cls_loss is : tensor(7.4152e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020839887512572593
now it is 23200 steps  and the cls_loss is : tensor(9.7205e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020742298963777757
now it is 23250 steps  and the cls_loss is : tensor(7.5418e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002064442479146562
now it is 23300 steps  and the cls_loss is : tensor(6.3265e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002054626986405149
now it is 23350 steps  and the cls_loss is : tensor(1.0320e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002044783906391589
now it is 23400 steps  and the cls_loss is : tensor(1.2152e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020349137287161683
now it is 23450 steps  and the cls_loss is : tensor(1.2619e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002025016944337054
now it is 23500 steps  and the cls_loss is : tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002015094045535872
now it is 23550 steps  and the cls_loss is : tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020051455258932203
now it is 23600 steps  and the cls_loss is : tensor(4.7753e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001995171880264119
now it is 23650 steps  and the cls_loss is : tensor(2.4198e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019851736047533934
now it is 23700 steps  and the cls_loss is : tensor(2.0932e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001975151196690997
now it is 23750 steps  and the cls_loss is : tensor(1.1062e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019651051546072766
now it is 23800 steps  and the cls_loss is : tensor(7.0987e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001955035978208171
now it is 23850 steps  and the cls_loss is : tensor(5.1484e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019449441683503565
now it is 23900 steps  and the cls_loss is : tensor(7.2069e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019348302270163337
now it is 23950 steps  and the cls_loss is : tensor(3.1827e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019246946572894562
now it is 24000 steps  and the cls_loss is : tensor(3.2321e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001914537963328909
now it is 24050 steps  and the cls_loss is : tensor(2.6977e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019043606503446307
now it is 24100 steps  and the cls_loss is : tensor(1.0857e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018941632245721804
now it is 24150 steps  and the cls_loss is : tensor(1.0210e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018839461932475604
now it is 24200 steps  and the cls_loss is : tensor(9.0587e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018737100645819839
now it is 24250 steps  and the cls_loss is : tensor(5.0110e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018634553477365951
now it is 24300 steps  and the cls_loss is : tensor(5.0386e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018531825527971443
now it is 24350 steps  and the cls_loss is : tensor(4.7666e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018428921907486138
now it is 24400 steps  and the cls_loss is : tensor(2.3350e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018325847734498033
now it is 24450 steps  and the cls_loss is : tensor(2.1361e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018222608136078654
now it is 24500 steps  and the cls_loss is : tensor(1.3306e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001811920824752806
now it is 24550 steps  and the cls_loss is : tensor(1.3342e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018015653212119385
now it is 24600 steps  and the cls_loss is : tensor(1.1747e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017911948180843024
now it is 24650 steps  and the cls_loss is : tensor(4.8254e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001780809831215039
now it is 24700 steps  and the cls_loss is : tensor(6.2671e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001770410877169735
now it is 24750 steps  and the cls_loss is : tensor(4.8172e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017599984732087255
now it is 24800 steps  and the cls_loss is : tensor(4.0767e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001749573137261365
now it is 24850 steps  and the cls_loss is : tensor(2.6862e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017391353879002665
now it is 24900 steps  and the cls_loss is : tensor(1.7394e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017286857443155057
now it is 24950 steps  and the cls_loss is : tensor(1.9618e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017182247262887951
now it is 25000 steps  and the cls_loss is : tensor(1.2679e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017077528541676297
now it is 25050 steps  and the cls_loss is : tensor(1.1730e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016972706488394052
now it is 25100 steps  and the cls_loss is : tensor(1.3298e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001686778631705506
now it is 25150 steps  and the cls_loss is : tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001676277324655372
now it is 25200 steps  and the cls_loss is : tensor(9.3872e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016657672500405385
now it is 25250 steps  and the cls_loss is : tensor(1.3349e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016552489306486523
now it is 25300 steps  and the cls_loss is : tensor(8.9833e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016447228896774688
now it is 25350 steps  and the cls_loss is : tensor(1.2074e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016341896507088276
now it is 25400 steps  and the cls_loss is : tensor(1.1206e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016236497376826058
now it is 25450 steps  and the cls_loss is : tensor(9.6151e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016131036748706614
now it is 25500 steps  and the cls_loss is : tensor(7.7246e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016025519868507509
now it is 25550 steps  and the cls_loss is : tensor(8.1786e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001591995198480438
now it is 25600 steps  and the cls_loss is : tensor(8.0451e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015814338348709856
now it is 25650 steps  and the cls_loss is : tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015708684213612354
now it is 25700 steps  and the cls_loss is : tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001560299483491479
now it is 25750 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015497275469773147
now it is 25800 steps  and the cls_loss is : tensor(8.1536e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001539153137683498
now it is 25850 steps  and the cls_loss is : tensor(4.9674e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015285767815977833
now it is 25900 steps  and the cls_loss is : tensor(4.8219e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001517999004804764
now it is 25950 steps  and the cls_loss is : tensor(2.3946e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015074203334596984
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.002645083332944556
generate label finished(24.63/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 26000 steps  and the cls_loss is : tensor(1.8810e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014968412937623446
now it is 26050 steps  and the cls_loss is : tensor(1.9255e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014862624119307808
now it is 26100 steps  and the cls_loss is : tensor(1.1391e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014756842141752336
now it is 26150 steps  and the cls_loss is : tensor(1.3764e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014651072266719024
now it is 26200 steps  and the cls_loss is : tensor(6.3016e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014545319755367866
now it is 26250 steps  and the cls_loss is : tensor(4.7288e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014439589867995168
now it is 26300 steps  and the cls_loss is : tensor(5.4789e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001433388786377187
now it is 26350 steps  and the cls_loss is : tensor(3.1784e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014228219000481965
now it is 26400 steps  and the cls_loss is : tensor(4.1104e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001412258853426097
now it is 26450 steps  and the cls_loss is : tensor(2.3818e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014017001719334474
now it is 26500 steps  and the cls_loss is : tensor(1.9651e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013911463807756762
now it is 26550 steps  and the cls_loss is : tensor(1.3736e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013805980049149606
now it is 26600 steps  and the cls_loss is : tensor(1.2273e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013700555690441128
now it is 26650 steps  and the cls_loss is : tensor(7.9177e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001359519597560479
now it is 26700 steps  and the cls_loss is : tensor(6.5649e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013489906145398574
now it is 26750 steps  and the cls_loss is : tensor(5.6663e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013384691437104297
now it is 26800 steps  and the cls_loss is : tensor(4.7513e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001327955708426709
now it is 26850 steps  and the cls_loss is : tensor(2.3831e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013174508316435066
now it is 26900 steps  and the cls_loss is : tensor(3.8694e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013069550358899215
now it is 26950 steps  and the cls_loss is : tensor(2.6656e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012964688432433485
now it is 27000 steps  and the cls_loss is : tensor(1.8181e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012859927753035086
now it is 27050 steps  and the cls_loss is : tensor(1.3543e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001275527353166502
now it is 27100 steps  and the cls_loss is : tensor(1.4360e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012650730973988921
now it is 27150 steps  and the cls_loss is : tensor(8.9400e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012546305280118088
now it is 27200 steps  and the cls_loss is : tensor(5.9582e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012442001644350842
now it is 27250 steps  and the cls_loss is : tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012337825254914116
now it is 27300 steps  and the cls_loss is : tensor(0.0267, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001223378129370543
now it is 27350 steps  and the cls_loss is : tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012129874936035114
now it is 27400 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012026111350368874
now it is 27450 steps  and the cls_loss is : tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011922495698070716
now it is 27500 steps  and the cls_loss is : tensor(6.0842e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001181903313314621
now it is 27550 steps  and the cls_loss is : tensor(6.0692e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011715728801986124
now it is 27600 steps  and the cls_loss is : tensor(3.7772e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011612587843110409
now it is 27650 steps  and the cls_loss is : tensor(3.0922e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001150961538691264
now it is 27700 steps  and the cls_loss is : tensor(2.5739e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011406816555404795
now it is 27750 steps  and the cls_loss is : tensor(1.9468e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011304196461962507
now it is 27800 steps  and the cls_loss is : tensor(1.6791e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011201760211070658
now it is 27850 steps  and the cls_loss is : tensor(1.1221e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011099512898069548
now it is 27900 steps  and the cls_loss is : tensor(1.0095e-05, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010997459608901388
now it is 27950 steps  and the cls_loss is : tensor(9.0903e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010895605419857352
now it is 28000 steps  and the cls_loss is : tensor(7.3188e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010793955397325047
now it is 28050 steps  and the cls_loss is : tensor(3.4199e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001069251459753653
now it is 28100 steps  and the cls_loss is : tensor(5.1915e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010591288066316776
now it is 28150 steps  and the cls_loss is : tensor(3.0510e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010490280838832723
now it is 28200 steps  and the cls_loss is : tensor(3.0295e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010389497939342772
now it is 28250 steps  and the cls_loss is : tensor(2.1051e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010288944380946912
now it is 28300 steps  and the cls_loss is : tensor(1.3811e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001018862516533735
now it is 28350 steps  and the cls_loss is : tensor(9.0701e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010088545282549697
now it is 28400 steps  and the cls_loss is : tensor(7.1285e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009988709710714784
now it is 28450 steps  and the cls_loss is : tensor(1.1282e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009889123415811035
now it is 28500 steps  and the cls_loss is : tensor(4.4533e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009789791351417438
now it is 28550 steps  and the cls_loss is : tensor(5.6488e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009690718458467154
now it is 28600 steps  and the cls_loss is : tensor(2.8036e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000959190966500176
now it is 28650 steps  and the cls_loss is : tensor(2.8062e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009493369885926097
now it is 28700 steps  and the cls_loss is : tensor(2.1583e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009395104022763824
now it is 28750 steps  and the cls_loss is : tensor(2.2596e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009297116963413565
now it is 28800 steps  and the cls_loss is : tensor(1.3302e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009199413581905825
now it is 28850 steps  and the cls_loss is : tensor(1.1020e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009101998738160516
now it is 28900 steps  and the cls_loss is : tensor(9.5224e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000900487727774525
now it is 28950 steps  and the cls_loss is : tensor(1.2857e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008908054031634252
now it is 29000 steps  and the cls_loss is : tensor(6.8207e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008811533815968128
now it is 29050 steps  and the cls_loss is : tensor(3.7990e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008715321431814267
now it is 29100 steps  and the cls_loss is : tensor(4.3145e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008619421664928023
now it is 29150 steps  and the cls_loss is : tensor(3.5198e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008523839285514687
now it is 29200 steps  and the cls_loss is : tensor(1.9372e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008428579047992198
now it is 29250 steps  and the cls_loss is : tensor(1.6744e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008333645690754649
now it is 29300 steps  and the cls_loss is : tensor(1.2712e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008239043935936583
now it is 29350 steps  and the cls_loss is : tensor(1.5285e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008144778489178126
now it is 29400 steps  and the cls_loss is : tensor(1.1027e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008050854039390916
now it is 29450 steps  and the cls_loss is : tensor(1.1024e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007957275258524858
now it is 29500 steps  and the cls_loss is : tensor(9.6966e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007864046801335741
now it is 29550 steps  and the cls_loss is : tensor(6.2455e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007771173305153711
now it is 29600 steps  and the cls_loss is : tensor(3.7458e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007678659389652584
now it is 29650 steps  and the cls_loss is : tensor(3.4084e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000758650965662008
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.004160167225274917
generate label finished(24.63/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 29700 steps  and the cls_loss is : tensor(2.9467e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007494728689728891
now it is 29750 steps  and the cls_loss is : tensor(2.3036e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007403321054308723
now it is 29800 steps  and the cls_loss is : tensor(1.3923e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007312291297119169
now it is 29850 steps  and the cls_loss is : tensor(1.2277e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007221643946123582
now it is 29900 steps  and the cls_loss is : tensor(1.0323e-09, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131383510263809
now it is 29950 steps  and the cls_loss is : tensor(9.8393e-10, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007041514479235943
now it is 30000 steps  and the cls_loss is : tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006952041323266989
now it is 30050 steps  and the cls_loss is : tensor(1.5636e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006862968492892477
now it is 30100 steps  and the cls_loss is : tensor(2.1759e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006774300418735153
now it is 30150 steps  and the cls_loss is : tensor(2.2116e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006686041511284519
now it is 30200 steps  and the cls_loss is : tensor(1.8067e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006598196160677502
now it is 30250 steps  and the cls_loss is : tensor(3.0467e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000651076873648004
now it is 30300 steps  and the cls_loss is : tensor(2.7886e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006423763587469768
now it is 30350 steps  and the cls_loss is : tensor(4.3606e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006337185041419691
now it is 30400 steps  and the cls_loss is : tensor(2.3490e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006251037404882908
now it is 30450 steps  and the cls_loss is : tensor(2.2201e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006165324962978392
now it is 30500 steps  and the cls_loss is : tensor(4.1197e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006080051979177861
now it is 30550 steps  and the cls_loss is : tensor(2.3991e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005995222695093695
now it is 30600 steps  and the cls_loss is : tensor(3.5921e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005910841330267945
now it is 30650 steps  and the cls_loss is : tensor(4.3728e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005826912081962462
now it is 30700 steps  and the cls_loss is : tensor(2.4768e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005743439124950105
now it is 30750 steps  and the cls_loss is : tensor(2.4325e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005660426611307083
now it is 30800 steps  and the cls_loss is : tensor(4.0563e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005577878670206443
now it is 30850 steps  and the cls_loss is : tensor(4.5084e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005495799407712635
now it is 30900 steps  and the cls_loss is : tensor(2.7490e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005414192906577322
now it is 30950 steps  and the cls_loss is : tensor(4.3850e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005333063226036269
now it is 31000 steps  and the cls_loss is : tensor(3.8587e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005252414401607419
now it is 31050 steps  and the cls_loss is : tensor(3.1446e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005172250444890195
now it is 31100 steps  and the cls_loss is : tensor(4.4308e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005092575343365929
now it is 31150 steps  and the cls_loss is : tensor(2.5437e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005013393060199524
now it is 31200 steps  and the cls_loss is : tensor(3.8449e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004934707534042326
now it is 31250 steps  and the cls_loss is : tensor(3.5781e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00048565226788362055
now it is 31300 steps  and the cls_loss is : tensor(4.4833e-08, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047788423836188723
now it is 31350 steps  and the cls_loss is : tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047016705123304305
now it is 31400 steps  and the cls_loss is : tensor(3.7874e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004625010903621166
now it is 31450 steps  and the cls_loss is : tensor(3.9082e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045488673706606356
now it is 31500 steps  and the cls_loss is : tensor(2.8836e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044732437009479647
now it is 31550 steps  and the cls_loss is : tensor(5.7550e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043981436561234716
now it is 31600 steps  and the cls_loss is : tensor(3.9784e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004323570971781535
now it is 31650 steps  and the cls_loss is : tensor(3.9334e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042495293572848063
now it is 31700 steps  and the cls_loss is : tensor(3.9891e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041760224955796836
now it is 31750 steps  and the cls_loss is : tensor(3.4505e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041030540430131174
now it is 31800 steps  and the cls_loss is : tensor(3.0282e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004030627629150745
now it is 31850 steps  and the cls_loss is : tensor(3.0200e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003958746856596342
now it is 31900 steps  and the cls_loss is : tensor(2.9758e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003887415300812632
now it is 31950 steps  and the cls_loss is : tensor(3.1621e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003816636509943418
now it is 32000 steps  and the cls_loss is : tensor(4.7162e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037464140046371226
now it is 32050 steps  and the cls_loss is : tensor(3.9267e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036767512778716456
now it is 32100 steps  and the cls_loss is : tensor(4.8278e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000360765179478062
now it is 32150 steps  and the cls_loss is : tensor(3.8666e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003539118992481045
now it is 32200 steps  and the cls_loss is : tensor(5.6156e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034711562799023344
now it is 32250 steps  and the cls_loss is : tensor(4.6126e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003403767037616744
now it is 32300 steps  and the cls_loss is : tensor(3.7662e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003336954617671207
now it is 32350 steps  and the cls_loss is : tensor(4.0166e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032707223434206125
now it is 32400 steps  and the cls_loss is : tensor(2.8481e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003205073509362486
now it is 32450 steps  and the cls_loss is : tensor(3.4239e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031400113809731213
now it is 32500 steps  and the cls_loss is : tensor(3.5087e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030755391945451547
now it is 32550 steps  and the cls_loss is : tensor(3.4829e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030116601570265674
now it is 32600 steps  and the cls_loss is : tensor(2.5375e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00029483774458611905
now it is 32650 steps  and the cls_loss is : tensor(3.5142e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00028856942088306486
now it is 32700 steps  and the cls_loss is : tensor(3.3061e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00028236135638977654
now it is 32750 steps  and the cls_loss is : tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027621385990514956
now it is 32800 steps  and the cls_loss is : tensor(7.2825e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027012723721533147
now it is 32850 steps  and the cls_loss is : tensor(8.0605e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00026410179107851095
now it is 32900 steps  and the cls_loss is : tensor(1.1691e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00025813782120985893
now it is 32950 steps  and the cls_loss is : tensor(0.0301, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002522356242666201
now it is 33000 steps  and the cls_loss is : tensor(2.4503e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002463954938333564
now it is 33050 steps  and the cls_loss is : tensor(2.0838e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00024061772040734453
now it is 33100 steps  and the cls_loss is : tensor(2.6896e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00023490259138412453
now it is 33150 steps  and the cls_loss is : tensor(3.0514e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022925039104320586
now it is 33200 steps  and the cls_loss is : tensor(2.9429e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022366140053392653
now it is 33250 steps  and the cls_loss is : tensor(2.6169e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00021813589786146817
now it is 33300 steps  and the cls_loss is : tensor(2.4669e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002126741578730265
now it is 33350 steps  and the cls_loss is : tensor(2.4672e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00020727645224414198
now it is 33400 steps  and the cls_loss is : tensor(2.6939e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000201943049465185
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.0029723769787252364
generate label finished(24.65/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

now it is 33450 steps  and the cls_loss is : tensor(2.5244e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00019667421482800105
now it is 33500 steps  and the cls_loss is : tensor(3.5104e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001914702104127145
now it is 33550 steps  and the cls_loss is : tensor(2.2731e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001863312950746929
now it is 33600 steps  and the cls_loss is : tensor(3.2333e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00018125772443167067
now it is 33650 steps  and the cls_loss is : tensor(1.9699e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017624975085103316
now it is 33700 steps  and the cls_loss is : tensor(2.7037e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017130762343726602
now it is 33750 steps  and the cls_loss is : tensor(2.4558e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016643158801956255
now it is 33800 steps  and the cls_loss is : tensor(2.2631e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016162188713959595
now it is 33850 steps  and the cls_loss is : tensor(2.2035e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001568787600394552
now it is 33900 steps  and the cls_loss is : tensor(2.4361e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00015220244264974473
now it is 33950 steps  and the cls_loss is : tensor(2.3351e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014759316757784893
now it is 34000 steps  and the cls_loss is : tensor(1.6440e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014305116409636215
now it is 34050 steps  and the cls_loss is : tensor(1.5472e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001385766581316833
now it is 34100 steps  and the cls_loss is : tensor(1.2438e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013416987225277913
now it is 34150 steps  and the cls_loss is : tensor(9.0709e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012983102566011255
now it is 34200 steps  and the cls_loss is : tensor(1.5889e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012556033417473997
now it is 34250 steps  and the cls_loss is : tensor(1.2152e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012135801022757427
now it is 34300 steps  and the cls_loss is : tensor(1.0121e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011722426284882088
now it is 34350 steps  and the cls_loss is : tensor(9.3498e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011315929765757833
now it is 34400 steps  and the cls_loss is : tensor(1.0453e-06, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010916331685161015
now it is 34450 steps  and the cls_loss is : tensor(6.6026e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010523651919728913
now it is 34500 steps  and the cls_loss is : tensor(3.3460e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010137910001970857
now it is 34550 steps  and the cls_loss is : tensor(4.5204e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.759125119296731e-05
now it is 34600 steps  and the cls_loss is : tensor(5.3809e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.38731611306259e-05
now it is 34650 steps  and the cls_loss is : tensor(4.8682e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.022501477633357e-05
now it is 34700 steps  and the cls_loss is : tensor(2.4855e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.664699359462985e-05
now it is 34750 steps  and the cls_loss is : tensor(3.7169e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.313927556191804e-05
now it is 34800 steps  and the cls_loss is : tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.970203515761136e-05
now it is 34850 steps  and the cls_loss is : tensor(3.0084e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.633544335545568e-05
now it is 34900 steps  and the cls_loss is : tensor(3.7338e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.303966761502402e-05
now it is 34950 steps  and the cls_loss is : tensor(3.5955e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.981487187338738e-05
now it is 35000 steps  and the cls_loss is : tensor(3.9102e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.666121653695912e-05
now it is 35050 steps  and the cls_loss is : tensor(3.4390e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.357885847351755e-05
now it is 35100 steps  and the cls_loss is : tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.0567951004402545e-05
now it is 35150 steps  and the cls_loss is : tensor(3.7228e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.762864389688876e-05
now it is 35200 steps  and the cls_loss is : tensor(4.6943e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.476108335673623e-05
now it is 35250 steps  and the cls_loss is : tensor(4.0195e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.1965412020917724e-05
now it is 35300 steps  and the cls_loss is : tensor(4.8076e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.924176895052436e-05
now it is 35350 steps  and the cls_loss is : tensor(3.7509e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.659028962384736e-05
now it is 35400 steps  and the cls_loss is : tensor(5.7823e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.401110592964e-05
now it is 35450 steps  and the cls_loss is : tensor(2.9163e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.150434616055743e-05
now it is 35500 steps  and the cls_loss is : tensor(6.2045e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.90701350067745e-05
now it is 35550 steps  and the cls_loss is : tensor(4.7543e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.670859354978365e-05
now it is 35600 steps  and the cls_loss is : tensor(4.4721e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.441983925637273e-05
now it is 35650 steps  and the cls_loss is : tensor(5.9004e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.2203985972780956e-05
now it is 35700 steps  and the cls_loss is : tensor(4.8044e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.006114391903713e-05
now it is 35750 steps  and the cls_loss is : tensor(5.3400e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.7991419683476428e-05
now it is 35800 steps  and the cls_loss is : tensor(4.6227e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.5994916217438678e-05
now it is 35850 steps  and the cls_loss is : tensor(6.6751e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.4071732830147528e-05
now it is 35900 steps  and the cls_loss is : tensor(4.1190e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.2221965183770435e-05
now it is 35950 steps  and the cls_loss is : tensor(5.4651e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.0445705288660185e-05
now it is 36000 steps  and the cls_loss is : tensor(3.7004e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.874304149877894e-05
now it is 36050 steps  and the cls_loss is : tensor(4.3724e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.7114058507302463e-05
now it is 36100 steps  and the cls_loss is : tensor(4.0690e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.555883734240735e-05
now it is 36150 steps  and the cls_loss is : tensor(5.0131e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.4077455363241644e-05
now it is 36200 steps  and the cls_loss is : tensor(5.0397e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.2669986256075445e-05
now it is 36250 steps  and the cls_loss is : tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.1336500030636549e-05
now it is 36300 steps  and the cls_loss is : tensor(5.9052e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0077063016628093e-05
now it is 36350 steps  and the cls_loss is : tensor(4.6905e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.891737860428403e-06
now it is 36400 steps  and the cls_loss is : tensor(5.2041e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.780583521975846e-06
now it is 36450 steps  and the cls_loss is : tensor(5.6531e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.7436552718353765e-06
now it is 36500 steps  and the cls_loss is : tensor(4.6468e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.781004688449589e-06
now it is 36550 steps  and the cls_loss is : tensor(3.6342e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.892679655573137e-06
now it is 36600 steps  and the cls_loss is : tensor(6.0825e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.078724359890492e-06
now it is 36650 steps  and the cls_loss is : tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.339179288819221e-06
now it is 36700 steps  and the cls_loss is : tensor(3.8601e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.6740812284941248e-06
now it is 36750 steps  and the cls_loss is : tensor(4.4742e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.083463261939546e-06
now it is 36800 steps  and the cls_loss is : tensor(5.3895e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.567354767422205e-06
now it is 36850 steps  and the cls_loss is : tensor(4.5337e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.1257814169908837e-06
now it is 36900 steps  and the cls_loss is : tensor(4.2258e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.587651751984601e-07
now it is 36950 steps  and the cls_loss is : tensor(3.7239e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.6632429801029096e-07
now it is 37000 steps  and the cls_loss is : tensor(3.9105e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.484733318959494e-07
now it is 37050 steps  and the cls_loss is : tensor(5.4069e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0522311310497719e-07
now it is 37100 steps  and the cls_loss is : tensor(4.4956e-07, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.6580767128653965e-08
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.003257556743128236
generate label finished(24.99/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00
Car AP@0.70, 0.50, 0.50:
bbox AP:0.00, 0.00, 0.00
bev  AP:0.00, 0.00, 0.00
3d   AP:0.00, 0.00, 0.00

model: {
  second: {
    voxel_generator {
      point_cloud_range : [0, -40, -3, 70.4, 40, 1]
      #point_cloud_range: [0, -96.0, -20, 96.0, 96.0, 20]
      # point_cloud_range : [0, -32.0, -3, 52.8, 32.0, 1]
      #voxel_size : [0.2, 0.2, 1.0]   # original is 0.05,0.05,0.1
      voxel_size : [0.05, 0.05, 0.1]   # original is 0.05,0.05,0.1
      max_number_of_points_per_voxel : 5   # original is 5
    }

    voxel_feature_extractor: {
      module_class_name: "VoxelFeatureExtractorV3"
      num_filters: [16]
      with_distance: false
      num_input_features: 4
    }
    middle_feature_extractor: {
      module_class_name: "SpMiddleFHD"
      # num_filters_down1: [] # protobuf don't support empty list.
      # num_filters_down2: []
      downsample_factor: 8
      num_input_features: 4
    }
    rpn: {
      module_class_name: "RPNV2"
      layer_nums: [5, 5]
      layer_strides: [1, 2]
      num_filters: [128, 256]
      upsample_strides: [1, 2]
      num_upsample_filters: [256, 256]
      use_groupnorm: false
      num_groups: 32
      num_input_features: 128
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0   #original 1.0
      localization_weight: 2.0
    }
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true # this can help for orientation benchmark
    direction_loss_weight: 0.2 # enough.
    use_aux_classifier: false
    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    #post_center_limit_range: [0, -96.0, -20, 96.0, 96.0, 0]
    post_center_limit_range: [0, -40, -3.0, 70.4, 40, 0.0]
    use_rotate_nms: true
    use_multi_class_nms: false
    nms_pre_max_size: 1000
    nms_post_max_size: 100
    nms_score_threshold: 0.2
    nms_iou_threshold: 0.01

    use_bev: false
    num_point_features: 4
    without_reflectivity: false
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      anchor_generators: {
        anchor_generator_range: {
          sizes: [1.6, 3.9, 1.56] # wlh
          anchor_ranges: [0, -40.0, -1.78, 70.4, 40.0, -1.78] # carefully set z center, the original one is -1.78
          rotations: [0, 1.57] # DON'T modify this unless you are very familiar with my code.
          matched_threshold : 0.6
          unmatched_threshold : 0.45
          class_name: "Car"
        }
      }
      sample_positive_fraction : -1
      sample_size : 512
      region_similarity_calculator: {
        nearest_iou_similarity: {
        }
      }
    }
  }
}


train_input_reader: {
  max_num_epochs : 160
  batch_size: 1
  prefetch_size : 25
  max_number_of_voxels: 16000 # to support batchsize=2 in 1080Ti, original 16000
  shuffle_points: true
  num_workers: 3
  groundtruth_localization_noise_std: [1.0, 1.0, 0.5]
  # groundtruth_rotation_uniform_noise: [-0.3141592654, 0.3141592654]
  # groundtruth_rotation_uniform_noise: [-1.57, 1.57]
  groundtruth_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_scaling_uniform_noise: [0.95, 1.05]
  global_random_rotation_range_per_object: [0, 0] # pi/4 ~ 3pi/4
  anchor_area_threshold: -1
  remove_points_after_sample: true
  groundtruth_points_drop_percentage: 0.0
  groundtruth_drop_max_keep_points: 15
  database_sampler {
    database_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_dbinfos_train.pkl"
    sample_groups {
      name_to_max_num {
        key: "Car"
        value: 15
      }
    }
    database_prep_steps {
      filter_by_min_num_points {
        min_num_point_pairs {
          key: "Car"
          value: 5
        }
      }
    }
    database_prep_steps {
      filter_by_difficulty {
        removed_difficulties: [-1]
      }
    }
    global_random_rotation_range_per_object: [0, 0]
    rate: 1.0
  }

  remove_unknown_examples: false
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_train.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

train_config: {
  optimizer: {
    adam_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3  # original 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0  #original 10
          pct_start: 0.4
        }
      }
      weight_decay: 0.01 # super converge. decrease this when you increase steps. og 0.01
    }
    fixed_weight_decay: true
    use_moving_average: false
  }
  steps: 37120 #112215 #113715 #111360 # 619 * 50, super converge. increase this to achieve slightly better results original 30950
  steps_per_eval: 3712 #7481 # 619 * 5
  save_checkpoints_secs : 1800 # half hour 1800
  save_summary_steps : 10
  enable_mixed_precision: false # for fp16 training, don't use this.
  loss_scale_factor : 512.0
  clear_metrics_every_epoch: true
  detection_2d_path: "../d2_detection_data"
}

eval_input_reader: {
  batch_size: 1
  max_num_epochs : 160
  prefetch_size : 25
  max_number_of_voxels: 16000
  shuffle_points: false
  num_workers: 3
  anchor_area_threshold: -1
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_val.pkl"
  #kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original/data/kitti/kitti_infos_test.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

now it is 50 steps  and the cls_loss is : tensor(2847.1541, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003000725556911313
now it is 100 steps  and the cls_loss is : tensor(527.3225, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300296159683897
now it is 150 steps  and the cls_loss is : tensor(233.1730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003006708197788306
now it is 200 steps  and the cls_loss is : tensor(151.4529, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003011964940447371
now it is 250 steps  and the cls_loss is : tensor(114.3898, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003018731236492261
now it is 300 steps  and the cls_loss is : tensor(54.6064, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003027006328652909
model: {
  second: {
    voxel_generator {
      point_cloud_range : [0, -40, -3, 70.4, 40, 1]
      #point_cloud_range: [0, -96.0, -20, 96.0, 96.0, 20]
      # point_cloud_range : [0, -32.0, -3, 52.8, 32.0, 1]
      #voxel_size : [0.2, 0.2, 1.0]   # original is 0.05,0.05,0.1
      voxel_size : [0.05, 0.05, 0.1]   # original is 0.05,0.05,0.1
      max_number_of_points_per_voxel : 5   # original is 5
    }

    voxel_feature_extractor: {
      module_class_name: "VoxelFeatureExtractorV3"
      num_filters: [16]
      with_distance: false
      num_input_features: 4
    }
    middle_feature_extractor: {
      module_class_name: "SpMiddleFHD"
      # num_filters_down1: [] # protobuf don't support empty list.
      # num_filters_down2: []
      downsample_factor: 8
      num_input_features: 4
    }
    rpn: {
      module_class_name: "RPNV2"
      layer_nums: [5, 5]
      layer_strides: [1, 2]
      num_filters: [128, 256]
      upsample_strides: [1, 2]
      num_upsample_filters: [256, 256]
      use_groupnorm: false
      num_groups: 32
      num_input_features: 128
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0   #original 1.0
      localization_weight: 2.0
    }
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true # this can help for orientation benchmark
    direction_loss_weight: 0.2 # enough.
    use_aux_classifier: false
    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    #post_center_limit_range: [0, -96.0, -20, 96.0, 96.0, 0]
    post_center_limit_range: [0, -40, -3.0, 70.4, 40, 0.0]
    use_rotate_nms: true
    use_multi_class_nms: false
    nms_pre_max_size: 1000
    nms_post_max_size: 100
    nms_score_threshold: 0.2
    nms_iou_threshold: 0.01

    use_bev: false
    num_point_features: 4
    without_reflectivity: false
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      anchor_generators: {
        anchor_generator_range: {
          sizes: [1.6, 3.9, 1.56] # wlh
          anchor_ranges: [0, -40.0, -1.78, 70.4, 40.0, -1.78] # carefully set z center, the original one is -1.78
          rotations: [0, 1.57] # DON'T modify this unless you are very familiar with my code.
          matched_threshold : 0.6
          unmatched_threshold : 0.45
          class_name: "Car"
        }
      }
      sample_positive_fraction : -1
      sample_size : 512
      region_similarity_calculator: {
        nearest_iou_similarity: {
        }
      }
    }
  }
}


train_input_reader: {
  max_num_epochs : 160
  batch_size: 1
  prefetch_size : 25
  max_number_of_voxels: 16000 # to support batchsize=2 in 1080Ti, original 16000
  shuffle_points: true
  num_workers: 3
  groundtruth_localization_noise_std: [1.0, 1.0, 0.5]
  # groundtruth_rotation_uniform_noise: [-0.3141592654, 0.3141592654]
  # groundtruth_rotation_uniform_noise: [-1.57, 1.57]
  groundtruth_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_scaling_uniform_noise: [0.95, 1.05]
  global_random_rotation_range_per_object: [0, 0] # pi/4 ~ 3pi/4
  anchor_area_threshold: -1
  remove_points_after_sample: true
  groundtruth_points_drop_percentage: 0.0
  groundtruth_drop_max_keep_points: 15
  database_sampler {
    database_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_dbinfos_train.pkl"
    sample_groups {
      name_to_max_num {
        key: "Car"
        value: 15
      }
    }
    database_prep_steps {
      filter_by_min_num_points {
        min_num_point_pairs {
          key: "Car"
          value: 5
        }
      }
    }
    database_prep_steps {
      filter_by_difficulty {
        removed_difficulties: [-1]
      }
    }
    global_random_rotation_range_per_object: [0, 0]
    rate: 1.0
  }

  remove_unknown_examples: false
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_train.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

train_config: {
  optimizer: {
    adam_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3  # original 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0  #original 10
          pct_start: 0.4
        }
      }
      weight_decay: 0.01 # super converge. decrease this when you increase steps. og 0.01
    }
    fixed_weight_decay: true
    use_moving_average: false
  }
  steps: 37120 #112215 #113715 #111360 # 619 * 50, super converge. increase this to achieve slightly better results original 30950
  steps_per_eval: 3712 #7481 # 619 * 5
  save_checkpoints_secs : 1800 # half hour 1800
  save_summary_steps : 10
  enable_mixed_precision: false # for fp16 training, don't use this.
  loss_scale_factor : 512.0
  clear_metrics_every_epoch: true
  detection_2d_path: "../d2_detection_data"
}

eval_input_reader: {
  batch_size: 1
  max_num_epochs : 160
  prefetch_size : 25
  max_number_of_voxels: 16000
  shuffle_points: false
  num_workers: 3
  anchor_area_threshold: -1
  remove_environment: false
  kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti/kitti_infos_val.pkl"
  #kitti_info_path: "/home/mingi/perception_ws/CLOCs-kitti-original/data/kitti/kitti_infos_test.pkl"
  kitti_root_path: "/home/mingi/perception_ws/CLOCs-kitti-original-mod/data/kitti"
}

now it is 50 steps  and the cls_loss is : tensor(2855.0896, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003000725556911313
